# -*- coding: utf-8 -*-
"""pipeline_non_literature.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VsrHiNVrVnIKRLShTo93UgfxOracL827
"""

import os

if __name__ == "__main__":  # ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ
    try:
        from google.colab import drive
        drive.mount('/content/drive')
    except:
        pass

import os
os.environ["OPENAI_API_KEY"] = "  "

import re
import json
import cv2
import base64
import numpy as np
import unicodedata
import easyocr
from PIL import Image
from openai import OpenAI
from IPython.display import display
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# âœ… ì„¤ì •
client = OpenAI()
reader = easyocr.Reader(['ko', 'en'], gpu=True)
model = SentenceTransformer("jhgan/ko-sroberta-multitask")

# âœ… ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
def normalize_filename(fn):
    return unicodedata.normalize('NFC', fn)

# âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_with_underlines(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    results = reader.readtext(gray, detail=True)
    full_text = " ".join([text for (_, text, _) in results])
    return re.sub(r'\b1[\.\)]', 'â‘ ', full_text)\
             .replace('2.', 'â‘¡')\
             .replace('3.', 'â‘¢')\
             .replace('4.', 'â‘£')\
             .replace('5.', 'â‘¤')\
             .strip()

# âœ… GPT í”„ë¡¬í”„íŠ¸
text_prompt = '''
ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:

1. ì§ˆë¬¸ ì¡°ê±´ì„ ì •í™•íˆ ë°˜ì˜í•´ ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”.
2. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
3. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.

[ì§€ë¬¸]
{passage}

[ë¬¸ì œ]
{question}

ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

[ì •ë‹µ] â‘¢
[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)
       â‘  ì˜¤ë‹µì¸ ì´ìœ  ...
       â‘¡ ì˜¤ë‹µì¸ ì´ìœ  ...
       â‘£ ì˜¤ë‹µì¸ ì´ìœ  ...
       â‘¤ ì˜¤ë‹µì¸ ì´ìœ  ...
'''

# âœ… GPT ì§ˆì˜
def ask_gpt(prompt_text):
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt_text}],
        temperature=0.3
    )
    return resp.choices[0].message.content

# âœ… GPT íƒœê¹…ìš© í”„ë¡¬í”„íŠ¸
tag_prompt = '''
ì•„ë˜ëŠ” êµ­ì–´ ì˜ì—­ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤.
ì´ ë¬¸ì œì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ íƒœê·¸ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”(ìµœëŒ€ 6ê°œ):
- ì¶œì œ ì˜ì—­(ë¹„ë¬¸í•™)
- ì¥ë¥´('ì¸ë¬¸-ì–¸ì–´', 'ì¸ë¬¸-ì² í•™', 'ì‚¬íšŒ-ê²½ì œ', 'ê¸°ìˆ -ì»´í“¨í„°', 'ì‚¬íšŒ-ë²•', 'ê³¼í•™-ìƒë¬¼', 'ì¸ë¬¸-ì—­ì‚¬', 'ê³¼í•™-í™”í•™', 'ì¸ë¬¸-ì‹¬ë¦¬', 'ì˜ˆìˆ -ë¯¸ìˆ ', 'ê³¼í•™-ë¬¼ë¦¬', 'ì‚¬íšŒ-ì •ì¹˜', 'ì˜ˆìˆ -ìŒì•…', 'ì˜ˆìˆ -ì˜í™”')
- ë¬¸ì œ ìœ í˜•(ë‹¨ì¼ë¬¸ì œ/ë³µí•©ë¬¸ì œ)
- ì£¼ìš” ì£¼ì œ ë˜ëŠ” í‚¤ì›Œë“œ

ì§€ë¬¸ì´ (ê°€), (ë‚˜)ë¡œ ì´ë£¨ì–´ì§€ë©´ ë³µí•©ë¬¸ì œì…ë‹ˆë‹¤.

íƒœê·¸ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
ì˜ˆ) ë¹„ë¬¸í•™, ì‚¬íšŒ-ê²½ì œ, ë³µí•©ë¬¸ì œ, ê³µê³µì¬, ì •ì±… ë”œë ˆë§ˆ, ì§€ë°© ì •ë¶€ ì¬ì • ì§€ì›
'''

def tag_from_image(image_path):
    with open(image_path, "rb") as f:
        base64_img = base64.b64encode(f.read()).decode("utf-8")

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” êµ­ì–´ ë¬¸ì œ íƒœê¹… ì „ë¬¸ê°€ì•¼."},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "ì´ êµ­ì–´ ì§€ë¬¸ ì´ë¯¸ì§€ë¥¼ ë³´ê³  íƒœê¹…í•´ ì¤˜:\n" + tag_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
                ]
            }
        ],
        temperature=0.2
    )

    tags = response.choices[0].message.content.strip().split(",")
    tags = [t.strip() for t in tags if t.strip()]
    return {
        "passage": "[ì´ë¯¸ì§€ ê¸°ë°˜ ì§€ë¬¸ ìƒëµ]",
        "genre": tags[1],
        "question_type": "ë³µí•©ë¬¸ì œ" if "ë³µí•©" in tags[2] else "ë‹¨ì¼ë¬¸ì œ",
        "keywords": tags[3:]
    }

# âœ… ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ
with open("/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¹„ë¬¸í•™/data/non-literature_cleaned.json", encoding="utf-8") as f:
    data = json.load(f)

passages = [item["passage"] for item in data]
embeddings = model.encode(passages, convert_to_tensor=False)

def recommend_for_external_problem(target_problem, top_n=2):
    target_passage = target_problem["passage"]
    target_keywords = target_problem["keywords"]
    target_type = target_problem["question_type"]
    target_genre = target_problem["genre"]

    target_embedding = model.encode(target_passage, convert_to_tensor=False)
    passage_similarities = cosine_similarity([target_embedding], embeddings)[0]

    target_kw_string = " ".join(target_keywords)
    target_kw_embedding = model.encode(target_kw_string, convert_to_tensor=False)

    results = []
    for idx, item in enumerate(data):
        if target_genre not in item["genre"]:
          continue
        item_kw_string = " ".join(item["keywords"])
        item_kw_embedding = model.encode(item_kw_string, convert_to_tensor=False)
        keyword_sim = cosine_similarity([target_kw_embedding], [item_kw_embedding])[0][0]
        passage_sim = passage_similarities[idx]
        final_score = 0.5 * keyword_sim + 0.5 * passage_sim
        if item["question_type"] == target_type:
            final_score += 0.2

        results.append({
            "year": item["year"],
            "month": item["month"],
            "pNum": item["pNum"],
            "start_Qnum": item.get("start_Qnum"),
            "end_Qnum": item.get("end_Qnum"),
            "score": round(final_score, 4),
            "preview": item["passage"][:100]
        })

    return sorted(results, key=lambda x: x["score"], reverse=True)[:top_n]

# âœ… ìœ ì‚¬ ë¬¸ì œ ì´ë¯¸ì§€ ì¶œë ¥
def show_problem_image_set(similar_problems, image_base="/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¹„ë¬¸í•™/data/img"):
    for i, p in enumerate(similar_problems, 1):
        year, month, pNum = p["year"], p["month"], p["pNum"]
        print(f"\n--- ìœ ì‚¬ ë¬¸ì œ {i} --- \n\t{year}-{month}\n")
        img_path = os.path.join(image_base, f"{year}-{month}-êµ­ì–´_p{pNum}.png")
        if os.path.exists(img_path):
            display(Image.open(img_path))
        for q in range(p.get("start_Qnum", 0), p.get("end_Qnum", 0) + 1):
            q_path = os.path.join(image_base, f"{year}-{month}-êµ­ì–´_{q}.png")
            if os.path.exists(q_path):
                display(Image.open(q_path))

# âœ… í†µí•© ì‹¤í–‰ í•¨ìˆ˜
def solve_and_recommend(passage_img_path, question_img_path):
    if not os.path.exists(passage_img_path) or not os.path.exists(question_img_path):
        print("âŒ ì§€ë¬¸ ë˜ëŠ” ë¬¸ì œ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    passage_text = extract_text_with_underlines(passage_img_path)
    question_text = extract_text_with_underlines(question_img_path)

    prompt = text_prompt.format(passage=passage_text, question=question_text)
    print("ğŸ“˜ GPT ë‹µë³€ ë° í•´ì„¤:")
    try:
        gpt_output = ask_gpt(prompt)
        print(gpt_output)
    except Exception as e:
        print(f"âš ï¸ GPT ì‹¤íŒ¨: {e}")
        return

    print("\n\nğŸ”– ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ:")
    try:
        external_problem = tag_from_image(passage_img_path)
        similar_problems = recommend_for_external_problem(external_problem)
        if similar_problems:
            show_problem_image_set(similar_problems)
        else:
            print("ì¶”ì²œëœ ìœ ì‚¬ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âš ï¸ ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ ì‹¤íŒ¨: {e}")

def attach_image_paths(problem, base_path):
    year, month, pNum = problem["year"], problem["month"], problem["pNum"]

    problem["passage_img"] = os.path.join(base_path, f"{year}-{month}-êµ­ì–´_p{pNum}.png")

    problem["problem_imgs"] = []
    for q in range(problem.get("start_Qnum", 0), problem.get("end_Qnum", 0) + 1):
        img_path = os.path.join(base_path, f"{year}-{month}-êµ­ì–´_{q}.png")
        if os.path.exists(img_path):
            problem["problem_imgs"].append((q, img_path))
    return problem

def pipeline_non_literature(passage_img_path, question_img_path, top_k=2):
    # 1. ì´ë¯¸ì§€ OCR
    passage_text = extract_text_with_underlines(passage_img_path)
    question_text = extract_text_with_underlines(question_img_path)

    # 2. GPT ì‘ë‹µ
    prompt = text_prompt.format(passage=passage_text, question=question_text)
    try:
        gpt_output = ask_gpt(prompt)
    except Exception as e:
        gpt_output = f"âš ï¸ GPT ì‘ë‹µ ì‹¤íŒ¨: {e}"

    # 3. íƒœê¹… ë° ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ
    # âœ… âœ… ì£¼ì˜: '.../img/ë¹„ë¬¸í•™' âŒ â†’ '.../img' âœ…
    image_base_path = "/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¹„ë¬¸í•™/data/img"

    try:
        # GPTë¡œ ì§€ë¬¸ íƒœê¹…
        tags = tag_from_image(passage_img_path)

        # íƒœê¹… ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ
        similar_raw = recommend_for_external_problem(tags, top_n=top_k)

        # ì¶”ì²œëœ ë¬¸ì œì— ì´ë¯¸ì§€ ê²½ë¡œ ë¶™ì´ê¸°
        similar = [attach_image_paths(p, image_base_path) for p in similar_raw]

    except Exception as e:
        similar = []
        gpt_output += f"\n\nâš ï¸ ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ ì‹¤íŒ¨: {e}"

    return gpt_output, similar