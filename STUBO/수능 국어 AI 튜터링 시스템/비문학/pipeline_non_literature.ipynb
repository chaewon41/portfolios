{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GgH1nZsVHXF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":  # ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuFT1ZK2rsf8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-OSdCGuSwY4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "from IPython.display import display\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# âœ… ì„¤ì •\n",
    "client = OpenAI()\n",
    "reader = easyocr.Reader(['ko', 'en'], gpu=True)\n",
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# âœ… ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\n",
    "def normalize_filename(fn):\n",
    "    return unicodedata.normalize('NFC', fn)\n",
    "\n",
    "# âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "def extract_text_with_underlines(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    results = reader.readtext(gray, detail=True)\n",
    "    full_text = \" \".join([text for (_, text, _) in results])\n",
    "    return re.sub(r'\\b1[\\.\\)]', 'â‘ ', full_text)\\\n",
    "             .replace('2.', 'â‘¡')\\\n",
    "             .replace('3.', 'â‘¢')\\\n",
    "             .replace('4.', 'â‘£')\\\n",
    "             .replace('5.', 'â‘¤')\\\n",
    "             .strip()\n",
    "\n",
    "# âœ… GPT í”„ë¡¬í”„íŠ¸\n",
    "text_prompt = '''\n",
    "ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "1. ì§ˆë¬¸ ì¡°ê±´ì„ ì •í™•íˆ ë°˜ì˜í•´ ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”.\n",
    "2. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "3. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.\n",
    "\n",
    "[ì§€ë¬¸]\n",
    "{passage}\n",
    "\n",
    "[ë¬¸ì œ]\n",
    "{question}\n",
    "\n",
    "ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
    "\n",
    "[ì •ë‹µ] â‘¢\n",
    "[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)\n",
    "       â‘  ì˜¤ë‹µì¸ ì´ìœ  ...\n",
    "       â‘¡ ì˜¤ë‹µì¸ ì´ìœ  ...\n",
    "       â‘£ ì˜¤ë‹µì¸ ì´ìœ  ...\n",
    "       â‘¤ ì˜¤ë‹µì¸ ì´ìœ  ...\n",
    "'''\n",
    "\n",
    "# âœ… GPT ì§ˆì˜\n",
    "def ask_gpt(prompt_text):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# âœ… GPT íƒœê¹…ìš© í”„ë¡¬í”„íŠ¸\n",
    "tag_prompt = '''\n",
    "ì•„ë˜ëŠ” êµ­ì–´ ì˜ì—­ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤.\n",
    "ì´ ë¬¸ì œì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ íƒœê·¸ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”(ìµœëŒ€ 6ê°œ):\n",
    "- ì¶œì œ ì˜ì—­(ë¹„ë¬¸í•™)\n",
    "- ì¥ë¥´('ì¸ë¬¸-ì–¸ì–´', 'ì¸ë¬¸-ì² í•™', 'ì‚¬íšŒ-ê²½ì œ', 'ê¸°ìˆ -ì»´í“¨í„°', 'ì‚¬íšŒ-ë²•', 'ê³¼í•™-ìƒë¬¼', 'ì¸ë¬¸-ì—­ì‚¬', 'ê³¼í•™-í™”í•™', 'ì¸ë¬¸-ì‹¬ë¦¬', 'ì˜ˆìˆ -ë¯¸ìˆ ', 'ê³¼í•™-ë¬¼ë¦¬', 'ì‚¬íšŒ-ì •ì¹˜', 'ì˜ˆìˆ -ìŒì•…', 'ì˜ˆìˆ -ì˜í™”')\n",
    "- ë¬¸ì œ ìœ í˜•(ë‹¨ì¼ë¬¸ì œ/ë³µí•©ë¬¸ì œ)\n",
    "- ì£¼ìš” ì£¼ì œ ë˜ëŠ” í‚¤ì›Œë“œ\n",
    "\n",
    "ì§€ë¬¸ì´ (ê°€), (ë‚˜)ë¡œ ì´ë£¨ì–´ì§€ë©´ ë³µí•©ë¬¸ì œì…ë‹ˆë‹¤.\n",
    "\n",
    "íƒœê·¸ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.\n",
    "ì˜ˆ) ë¹„ë¬¸í•™, ì‚¬íšŒ-ê²½ì œ, ë³µí•©ë¬¸ì œ, ê³µê³µì¬, ì •ì±… ë”œë ˆë§ˆ, ì§€ë°© ì •ë¶€ ì¬ì • ì§€ì›\n",
    "'''\n",
    "\n",
    "def tag_from_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        base64_img = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë„ˆëŠ” êµ­ì–´ ë¬¸ì œ íƒœê¹… ì „ë¬¸ê°€ì•¼.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"ì´ êµ­ì–´ ì§€ë¬¸ ì´ë¯¸ì§€ë¥¼ ë³´ê³  íƒœê¹…í•´ ì¤˜:\\n\" + tag_prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    tags = response.choices[0].message.content.strip().split(\",\")\n",
    "    tags = [t.strip() for t in tags if t.strip()]\n",
    "    return {\n",
    "        \"passage\": \"[ì´ë¯¸ì§€ ê¸°ë°˜ ì§€ë¬¸ ìƒëµ]\",\n",
    "        \"genre\": tags[1],\n",
    "        \"question_type\": \"ë³µí•©ë¬¸ì œ\" if \"ë³µí•©\" in tags[2] else \"ë‹¨ì¼ë¬¸ì œ\",\n",
    "        \"keywords\": tags[3:]\n",
    "    }\n",
    "\n",
    "# âœ… ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ\n",
    "with open(\"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¹„ë¬¸í•™/data/non-literature_cleaned.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "passages = [item[\"passage\"] for item in data]\n",
    "embeddings = model.encode(passages, convert_to_tensor=False)\n",
    "\n",
    "def recommend_for_external_problem(target_problem, top_n=2):\n",
    "    target_passage = target_problem[\"passage\"]\n",
    "    target_keywords = target_problem[\"keywords\"]\n",
    "    target_type = target_problem[\"question_type\"]\n",
    "    target_genre = target_problem[\"genre\"]\n",
    "\n",
    "    target_embedding = model.encode(target_passage, convert_to_tensor=False)\n",
    "    passage_similarities = cosine_similarity([target_embedding], embeddings)[0]\n",
    "\n",
    "    target_kw_string = \" \".join(target_keywords)\n",
    "    target_kw_embedding = model.encode(target_kw_string, convert_to_tensor=False)\n",
    "\n",
    "    results = []\n",
    "    for idx, item in enumerate(data):\n",
    "        if target_genre not in item[\"genre\"]:\n",
    "          continue\n",
    "        item_kw_string = \" \".join(item[\"keywords\"])\n",
    "        item_kw_embedding = model.encode(item_kw_string, convert_to_tensor=False)\n",
    "        keyword_sim = cosine_similarity([target_kw_embedding], [item_kw_embedding])[0][0]\n",
    "        passage_sim = passage_similarities[idx]\n",
    "        final_score = 0.5 * keyword_sim + 0.5 * passage_sim\n",
    "        if item[\"question_type\"] == target_type:\n",
    "            final_score += 0.2\n",
    "\n",
    "        results.append({\n",
    "            \"year\": item[\"year\"],\n",
    "            \"month\": item[\"month\"],\n",
    "            \"pNum\": item[\"pNum\"],\n",
    "            \"start_Qnum\": item.get(\"start_Qnum\"),\n",
    "            \"end_Qnum\": item.get(\"end_Qnum\"),\n",
    "            \"score\": round(final_score, 4),\n",
    "            \"preview\": item[\"passage\"][:100]\n",
    "        })\n",
    "\n",
    "    return sorted(results, key=lambda x: x[\"score\"], reverse=True)[:top_n]\n",
    "\n",
    "# âœ… ìœ ì‚¬ ë¬¸ì œ ì´ë¯¸ì§€ ì¶œë ¥\n",
    "def show_problem_image_set(similar_problems, image_base=\"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¹„ë¬¸í•™/data/img\"):\n",
    "    for i, p in enumerate(similar_problems, 1):\n",
    "        year, month, pNum = p[\"year\"], p[\"month\"], p[\"pNum\"]\n",
    "        print(f\"\\n--- ìœ ì‚¬ ë¬¸ì œ {i} --- \\n\\t{year}-{month}\\n\")\n",
    "        img_path = os.path.join(image_base, f\"{year}-{month}-êµ­ì–´_p{pNum}.png\")\n",
    "        if os.path.exists(img_path):\n",
    "            display(Image.open(img_path))\n",
    "        for q in range(p.get(\"start_Qnum\", 0), p.get(\"end_Qnum\", 0) + 1):\n",
    "            q_path = os.path.join(image_base, f\"{year}-{month}-êµ­ì–´_{q}.png\")\n",
    "            if os.path.exists(q_path):\n",
    "                display(Image.open(q_path))\n",
    "\n",
    "# âœ… í†µí•© ì‹¤í–‰ í•¨ìˆ˜\n",
    "def solve_and_recommend(passage_img_path, question_img_path):\n",
    "    if not os.path.exists(passage_img_path) or not os.path.exists(question_img_path):\n",
    "        print(\"âŒ ì§€ë¬¸ ë˜ëŠ” ë¬¸ì œ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    passage_text = extract_text_with_underlines(passage_img_path)\n",
    "    question_text = extract_text_with_underlines(question_img_path)\n",
    "\n",
    "    prompt = text_prompt.format(passage=passage_text, question=question_text)\n",
    "    print(\"ğŸ“˜ GPT ë‹µë³€ ë° í•´ì„¤:\")\n",
    "    try:\n",
    "        gpt_output = ask_gpt(prompt)\n",
    "        print(gpt_output)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPT ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\\nğŸ”– ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ:\")\n",
    "    try:\n",
    "        external_problem = tag_from_image(passage_img_path)\n",
    "        similar_problems = recommend_for_external_problem(external_problem)\n",
    "        if similar_problems:\n",
    "            show_problem_image_set(similar_problems)\n",
    "        else:\n",
    "            print(\"ì¶”ì²œëœ ìœ ì‚¬ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8H9LxLCdwfd"
   },
   "outputs": [],
   "source": [
    "def attach_image_paths(problem, base_path):\n",
    "    year, month, pNum = problem[\"year\"], problem[\"month\"], problem[\"pNum\"]\n",
    "\n",
    "    # ì§€ë¬¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "    problem[\"passage_img\"] = os.path.join(base_path, f\"{year}-{month}-êµ­ì–´_p{pNum}.png\")\n",
    "\n",
    "    # ë¬¸ì œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸\n",
    "    problem[\"problem_imgs\"] = []\n",
    "    for q in range(problem.get(\"start_Qnum\", 0), problem.get(\"end_Qnum\", 0) + 1):\n",
    "        img_path = os.path.join(base_path, f\"{year}-{month}-êµ­ì–´_{q}.png\")\n",
    "        if os.path.exists(img_path):\n",
    "            problem[\"problem_imgs\"].append((q, img_path))\n",
    "\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkYanUY-XbGp"
   },
   "outputs": [],
   "source": [
    "def pipeline_non_literature(passage_img_path, question_img_path, top_k=2):\n",
    "    # 1. ì´ë¯¸ì§€ OCR\n",
    "    passage_text = extract_text_with_underlines(passage_img_path)\n",
    "    question_text = extract_text_with_underlines(question_img_path)\n",
    "\n",
    "    # 2. GPT ì‘ë‹µ\n",
    "    prompt = text_prompt.format(passage=passage_text, question=question_text)\n",
    "    try:\n",
    "        gpt_output = ask_gpt(prompt)\n",
    "    except Exception as e:\n",
    "        gpt_output = f\"âš ï¸ GPT ì‘ë‹µ ì‹¤íŒ¨: {e}\"\n",
    "\n",
    "    # 3. íƒœê¹… ë° ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ\n",
    "    # âœ… âœ… ì£¼ì˜: '.../img/ë¹„ë¬¸í•™' âŒ â†’ '.../img' âœ…\n",
    "    image_base_path = \"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¹„ë¬¸í•™/data/img\"\n",
    "\n",
    "    try:\n",
    "        # GPTë¡œ ì§€ë¬¸ íƒœê¹…\n",
    "        tags = tag_from_image(passage_img_path)\n",
    "\n",
    "        # íƒœê¹… ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ\n",
    "        similar_raw = recommend_for_external_problem(tags, top_n=top_k)\n",
    "\n",
    "        # ì¶”ì²œëœ ë¬¸ì œì— ì´ë¯¸ì§€ ê²½ë¡œ ë¶™ì´ê¸°\n",
    "        similar = [attach_image_paths(p, image_base_path) for p in similar_raw]\n",
    "\n",
    "    except Exception as e:\n",
    "        similar = []\n",
    "        gpt_output += f\"\\n\\nâš ï¸ ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ ì‹¤íŒ¨: {e}\"\n",
    "\n",
    "    return gpt_output, similar"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
