{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axYSaRbgJzK4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":  # ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unOG6EKiKq8U"
   },
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œê³¼ ë‹µë³€ í•´ì„¤ì„ ë™ì‹œì— í•˜ëŠ” ìµœì¢… ëª¨ë¸\n",
    "import openai\n",
    "import os\n",
    "import base64\n",
    "import easyocr\n",
    "import pytesseract\n",
    "import re\n",
    "from PIL import Image\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# GPT client ì„¤ì •\n",
    "client = openai.OpenAI(api_key=\"  \")  # API í‚¤ ì…ë ¥ í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVKcf-2kH0N-"
   },
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/í™”ì‘\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "VECTOR_DB_PATH = os.path.join(BASE_DIR, \"outputs\")  # FAISS vector DBê°€ ì €ì¥ëœ í´ë”\n",
    "\n",
    "# [5] EasyOCR Reader\n",
    "reader = easyocr.Reader(['ko', 'en'])\n",
    "\n",
    "# [6] ì„ë² ë”© ëª¨ë¸ & ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "vectorstore = FAISS.load_local(VECTOR_DB_PATH, embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# [7] ì´ë¯¸ì§€ ì¸ì½”ë”©\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# [8] OCR í•¨ìˆ˜\n",
    "def easyocr_text(image_path):\n",
    "    result = reader.readtext(image_path, detail=0, paragraph=True)\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "def pytesseract_text(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(img, lang=\"kor+eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejWchETuy8rM"
   },
   "outputs": [],
   "source": [
    "def extract_problem_number(text: str) -> str:\n",
    "    match = re.match(r\"\\s*(\\d+)[\\.\\)]?\\s*ë¬¸ì œ\", text)\n",
    "    return match.group(1) if match else \"ë²ˆí˜¸ ì—†ìŒ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDr2eUN0Sd_b"
   },
   "outputs": [],
   "source": [
    "def analyze_problem(context_image_path, question_image_path, top_k=2):\n",
    "    result_dict = {}\n",
    "\n",
    "    # ğŸ”§ ë‚´ë¶€ ì„¤ì •\n",
    "    base_img_dir = \"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/í™”ì‘/data/output_images\"\n",
    "    page_map = {\n",
    "        \"p9\": [35, 36, 37],\n",
    "        \"p10\": [38, 39, 40, 41, 42],\n",
    "        \"p11\": [43, 44, 45],\n",
    "    }\n",
    "\n",
    "    # [1] GPT ì •ë‹µ/í•´ì„¤ ìƒì„±\n",
    "    context_text = easyocr_text(context_image_path)\n",
    "    question_text = easyocr_text(question_image_path)\n",
    "\n",
    "    c_b64 = encode_image(context_image_path)\n",
    "    q_b64 = encode_image(question_image_path)\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": (\n",
    "                        f\"ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ ì§€ë¬¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:\\n{context_text}\\n\\n\"\n",
    "                        f\"ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ ë¬¸ì œì™€ ì„ íƒì§€ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:\\n{question_text}\\n\\n\"\n",
    "                        \"ìœ„ ë‘ ì´ë¯¸ì§€ì™€ OCR í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ë¬¸ì œì˜ ì •ë‹µê³¼ í•´ì„¤ì„ ì•Œë ¤ì¤˜. \"\n",
    "                        \"ì •ë‹µ ë²ˆí˜¸ì™€ í•´ì„¤ì„ ë¶„ë¦¬í•´ì„œ ì•Œë ¤ì¤˜. (ì˜ˆ: ì •ë‹µ: â‘¢) \"\n",
    "                        \"ëª¨ë“  ì„ ì§€ì— ëŒ€í•œ í•´ì„¤ì„ ì œê³µí•´ì¤˜.\"\n",
    "                    )},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{c_b64}\"}},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{q_b64}\"}},\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=5000,\n",
    "    )\n",
    "\n",
    "    gpt_response = response.choices[0].message.content\n",
    "    full_text = pytesseract_text(question_image_path)\n",
    "\n",
    "    # [2] ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ\n",
    "    similar_docs = retriever.get_relevant_documents(full_text, k=top_k)\n",
    "    similar_problems = []\n",
    "\n",
    "    for i, doc in enumerate(similar_docs, 1):\n",
    "        meta = doc.metadata\n",
    "        year = str(meta.get(\"ë…„ë„\", \"ì—°ë„ ì—†ìŒ\"))\n",
    "        month = str(meta.get(\"ì›”\", \"ì›” ì—†ìŒ\")).zfill(2)\n",
    "        question_text = doc.page_content\n",
    "\n",
    "        # ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ\n",
    "        match = re.match(r\"\\s*(\\d+)[\\.\\)]?\", question_text)\n",
    "        problem_number = match.group(1) if match else \"ë²ˆí˜¸ì—†ìŒ\"\n",
    "\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ë¡ \n",
    "        problem_filename = f\"{year}-{month}-í™”ì‘_{problem_number}.png\"\n",
    "        passage_filename = meta.get(\"passage_img\", \"\")\n",
    "\n",
    "        # ì§€ë¬¸ ì¶”ë¡ \n",
    "        if not passage_filename and problem_number.isdigit():\n",
    "            for page, numbers in page_map.items():\n",
    "                if int(problem_number) in numbers:\n",
    "                    passage_filename = f\"{year}-{month}-í™”ì‘_{page}.png\"\n",
    "                    break\n",
    "\n",
    "        # ì „ì²´ ê²½ë¡œ ìƒì„±\n",
    "        passage_img_path = os.path.join(base_img_dir, passage_filename) if passage_filename else \"\"\n",
    "        problem_img_path = os.path.join(base_img_dir, problem_filename)\n",
    "\n",
    "        similar_problems.append({\n",
    "            \"index\": i,\n",
    "            \"year\": year,\n",
    "            \"month\": month,\n",
    "            \"answer\": meta.get(\"ë‹µ\", None),\n",
    "            \"explanation\": meta.get(\"í•´ì„¤\", None),\n",
    "            \"content\": question_text,\n",
    "            \"problem_number\": problem_number,\n",
    "            \"passage_img_path\": passage_img_path,\n",
    "            \"problem_img_path\": problem_img_path,\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"problem_number\": extract_problem_number(full_text),\n",
    "        \"gpt_response\": gpt_response,\n",
    "        \"similar_problems\": similar_problems,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMGE2j/fZufiHG3nj0PtVuw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
