{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BC67ybd_0zG"
   },
   "source": [
    "# **0. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ & api key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKc9Ou1b1KcO",
    "outputId": "4ab8aa4b-0090-4628-fdeb-02ebcf099cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":  # ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-rAxqSqaLz1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "#  API í‚¤ ì„¤ì •\n",
    "OPENAI_API_KEY = \" \"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etkd27vwoTOk"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAQbWzv88RgN"
   },
   "source": [
    "# **<Retriever (ë‹µë³€,í•´ì„¤ / ìœ ì‚¬ë¬¸ì œ ì¶”ì²œ)> í˜¸ì¶œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdiIAU-P8Q5h",
    "outputId": "bc73db26-37f1-47fb-be83-e4c045252a9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-6-3924990573.py:9: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
     ]
    }
   ],
   "source": [
    "# ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ\n",
    "VECTORSTORE_PATH = \"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¬¸í•™/faiss_index_ë‹µë³€í•´ì„¤\"\n",
    "\n",
    "# retriever ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜\n",
    "def get_retriever():\n",
    "    if not os.path.exists(VECTORSTORE_PATH):\n",
    "        raise FileNotFoundError(f\"âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {VECTORSTORE_PATH}\")\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(VECTORSTORE_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,\n",
    "            \"score_threshold\": 0.5\n",
    "        }\n",
    "    )\n",
    "    return retriever\n",
    "\n",
    "# retriever ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "retriever_literature_answer = get_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1rD7SEAqoVpM"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¹ ê²½ë¡œ ì„¤ì •\n",
    "index_path = \"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¬¸í•™/faiss_index_ìœ ì‚¬ë¬¸ì œ\"\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# ğŸ”¹ ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë“œ\n",
    "retriever_literature_recommend = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhkt0mXWELV8"
   },
   "source": [
    "# **<ì´ë¯¸ì§€(ì§€ë¬¸/ë¬¸í•­)ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ>**\n",
    "- ì§€ë¬¸ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œí• ë•Œ ë¹„ìš© ë¬¸ì œ ë°œìƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4a1G-36bXfE"
   },
   "source": [
    "### **ì§€ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ**\n",
    "ì´ë¯¸ì§€ 5ë“±ë¶„ -> gpt-4oë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ -> gpt-4oê°€ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•˜ë©´ íŠ¹ìˆ˜ë¬¸ì ì‚½ì… -> gpt-4oê°€ íŠ¹ìˆ˜ë¬¸ì ê²€í†  -> gpt-4oê°€ ì§€ë¬¸ ë²”ìœ„([A], [B] ë“±) ì‚½ì…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MqXc1UYbfq6"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import openai\n",
    "import base64\n",
    "import io\n",
    "from typing import List, Tuple\n",
    "\n",
    "# âœ… ì´ë¯¸ì§€ â†’ base64\n",
    "def image_to_base64(image: Image.Image) -> str:\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    return f\"data:image/png;base64,{base64.b64encode(buffer.getvalue()).decode()}\"\n",
    "\n",
    "# âœ… ì´ë¯¸ì§€ ìˆ˜ì§ ë¶„í• \n",
    "def split_image_vertically(image: Image.Image, parts: int = 5) -> List[Image.Image]:\n",
    "    width, height = image.size\n",
    "    part_height = height // parts\n",
    "    return [\n",
    "        image.crop((0, i * part_height, width, height if i == parts - 1 else (i + 1) * part_height))\n",
    "        for i in range(parts)\n",
    "    ]\n",
    "\n",
    "# âœ… GPTì—ê²Œ OCR ì‹œí‚¤ëŠ” í•¨ìˆ˜\n",
    "def gpt_ocr_text(image: Image.Image) -> str:\n",
    "    base64_img = image_to_base64(image)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ì˜ ì§€ë¬¸ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì „ë¬¸ê°€ì•¼.\n",
    "\n",
    "    ì•„ë˜ ì´ë¯¸ì§€ë¥¼ ë³´ê³  **OCR í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì¶”ì¶œ**í•´.\n",
    "    í…ìŠ¤íŠ¸ ì¶”ì¶œë§Œ í•˜ê³ , ì ˆëŒ€ ê°€ê³µí•˜ê±°ë‚˜ ì„¤ëª…í•˜ì§€ ë§ˆ.\n",
    "\n",
    "    ğŸ“Œ ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ:\n",
    "    - ì¤„ë°”ê¿ˆì€ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ê·¸ëŒ€ë¡œ ì‚´ë ¤ì•¼ í•´.\n",
    "    - ë„ì–´ì“°ê¸°, íŠ¹ìˆ˜ë¬¸ì, ê´„í˜¸, ë§ˆì¹¨í‘œ ë“± ëª¨ë“  ë¬¸ì¥ ë¶€í˜¸ë„ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•´.\n",
    "    - í•´ì„ì´ë‚˜ ë¶€ì—° ì„¤ëª… ì—†ì´ **ìˆœìˆ˜í•œ OCR ê²°ê³¼ë§Œ ì¶œë ¥**í•´ì•¼ í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\n",
    "                            \"url\": base64_img,\n",
    "                            \"detail\": \"high\"\n",
    "                        }}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=16000\n",
    "        )\n",
    "        output = response.choices[0].message.content.strip()\n",
    "        if not output or \"ì£„ì†¡í•˜ì§€ë§Œ\" in output:\n",
    "            raise ValueError(\"GPT OCR ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ\")\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        return f\"[âŒ GPT OCR ì‹¤íŒ¨]: {str(e)}\"\n",
    "\n",
    "# âœ… GPT-4oë¡œ íŠ¹ìˆ˜ê¸°í˜¸&ê´„í˜¸ ì‚½ì…\n",
    "def refine_text_with_gpt(image: Image.Image, ocr_output: str) -> str:\n",
    "    base64_img = image_to_base64(image)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ ì§€ë¬¸ ì •ë¦¬ ì „ë¬¸ê°€ì•¼.\n",
    "\n",
    "    ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ ì§€ë¬¸ê³¼ ì›ë³¸ ì´ë¯¸ì§€ì•¼. ë„ˆëŠ” ì´ ë‘ ì •ë³´ë¥¼ ë¹„êµí•´ì„œ ë‹¤ìŒê³¼ ê°™ì´ OCR ê²°ê³¼ë¥¼ ì •í™•í•˜ê²Œ ìˆ˜ì •í•´ì•¼ í•´.\n",
    "\n",
    "    ğŸ“Œ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:\n",
    "\n",
    "    1. âœ… ì´ë¯¸ì§€ ì•ˆì—ì„œ íŠ¹ìˆ˜ê¸°í˜¸(ì›í˜• ë¬¸ì/ì•ŒíŒŒë²³)ë¥¼ ì •í™•íˆ ì‹ë³„í•˜ê³ , OCR í…ìŠ¤íŠ¸ì˜ ì•Œë§ì€ ìœ„ì¹˜ì— ì‚½ì…í•´ì•¼ í•´.\n",
    "      - OCR ê²°ê³¼ë§Œ ë³´ë©´ ì•ˆ ë¼. ë°˜ë“œì‹œ ì´ë¯¸ì§€ì—ì„œ íŠ¹ìˆ˜ê¸°í˜¸ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•´.\n",
    "\n",
    "    2. âœ… ì‚½ì…í•´ì•¼ í•  íŠ¹ìˆ˜ê¸°í˜¸ëŠ” ë‹¤ìŒê³¼ ê°™ì•„:\n",
    "      - í•œê¸€ ì›í˜• ë¬¸ì: ã‰ , ã‰¡, ã‰¢, ã‰£, ã‰¤\n",
    "      - ì›í˜• ì•ŒíŒŒë²³: â“, â“‘, â“’, â““, â“”\n",
    "\n",
    "    3. âœ… **ëª¨ë“  íŠ¹ìˆ˜ê¸°í˜¸ ë’¤ì—ëŠ” ë°‘ì¤„ë¡œ ê°•ì¡°ëœ ë¬¸ì¥ì´ ë°˜ë“œì‹œ ìˆê³ **, ê·¸ **ê°•ì¡°ëœ ë¬¸ì¥ ì „ì²´ë¥¼ ê´„í˜¸ '( )'ë¡œ ë°˜ë“œì‹œ ê°ì‹¸ì•¼ í•´.**\n",
    "      - íŠ¹ìˆ˜ê¸°í˜¸ì™€ ê´„í˜¸ëŠ” ë¶™ì—¬ì„œ ì‘ì„±í•´: ì˜ˆ) â“(ê°•ì¡°ëœ ë¬¸ì¥)\n",
    "      - ê´„í˜¸ëŠ” í•´ë‹¹ ë¬¸ì¥ì˜ ì‹œì‘ê³¼ ëì„ ì •í™•íˆ ê°ì‹¸ì•¼ í•˜ë©°, ì¤„ë°”ê¿ˆì´ë‚˜ ê³µë°±ì´ ìˆì–´ë„ ì „ì²´ë¥¼ í¬í•¨í•´ì•¼ í•´.\n",
    "\n",
    "    4. âœ… í•œ íŠ¹ìˆ˜ê¸°í˜¸ì— í•´ë‹¹í•˜ëŠ” ê°•ì¡° ë¬¸ì¥ì´ **ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ ìˆë”ë¼ë„** ê´„í˜¸ë¡œ ì •í™•íˆ ê°ì‹¸ì•¼ í•´.\n",
    "      - ì¤‘ê°„ ì¤„ë°”ê¿ˆì´ë‚˜ ê³µë°±ì´ ìˆë”ë¼ë„ ê°•ì¡° ë¬¸ì¥ ì „ì²´ê°€ ê´„í˜¸ ì•ˆì— ë“¤ì–´ê°€ì•¼ í•´.\n",
    "\n",
    "    5. âŒ íŠ¹ìˆ˜ê¸°í˜¸ê°€ ì—†ëŠ” ë¬¸ì¥ì€ ìˆ˜ì •í•˜ì§€ ë§ˆ.\n",
    "      âŒ ì² ì ì˜¤ë¥˜, ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ë“± OCR ìì²´ ì˜¤ë¥˜ë„ ê³ ì¹˜ì§€ ë§ˆ.\n",
    "\n",
    "    6. âœ… ì¶œë ¥ì€ ë°˜ë“œì‹œ ì§€ë¬¸ ì „ì²´ë¥¼ í¬í•¨í•´ì•¼ í•˜ë©°, íŠ¹ìˆ˜ê¸°í˜¸ + ê°•ì¡°ë¬¸ì¥ ë¶€ë¶„ë§Œ ìˆ˜ì •í•´ì•¼ í•´.\n",
    "      âŒ ì„¤ëª…, í•´ì„¤, ì¶”ê°€ ì •ë³´ ì—†ì´ **ì§€ë¬¸ ì „ì²´ë§Œ ì¶œë ¥**í•´ì•¼ í•´.\n",
    "\n",
    "\n",
    "     âš ï¸ ë°˜ë“œì‹œ íŠ¹ìˆ˜ê¸°í˜¸ ë’¤ì—ëŠ” ë°‘ì¤„ë¡œ ê°•ì¡°ëœ ë¶€ë¶„ì´ ê´„í˜¸'()'ë¡œ ê°ì‹¸ì ¸ ìˆì–´ì•¼í•´.\n",
    "     âš ï¸ íŠ¹ìˆ˜ê¸°í˜¸ ë’¤ì— ê´„í˜¸ê°€ ì—†ë‹¤ë©´ ë‹¤ì‹œ ë°‘ì¤„ë¡œ ê°•ì¡°ëœ ë¶€ë¶„ì„ ë‹¤ì‹œ ì°¾ê³  ê´„í˜¸ë¥¼ ì¶”ê°€í•´ì¤˜.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": f\"OCR ì¶”ì¶œ ê²°ê³¼:\\n{ocr_output.strip()}\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\n",
    "                            \"url\": base64_img,\n",
    "                            \"detail\": \"auto\"\n",
    "                        }}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=16000  # ê°€ëŠ¥í•œ ìµœëŒ€ê°’ ì‚¬ìš©\n",
    "        )\n",
    "        output = response.choices[0].message.content.strip()\n",
    "        if not output or \"ì£„ì†¡í•˜ì§€ë§Œ\" in output or \"ë„ì™€ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\" in output:\n",
    "            raise ValueError(\"GPT ì‘ë‹µ ì˜¤ë¥˜ ë˜ëŠ” ë‚´ìš© ì—†ìŒ\")\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        return f\"[âŒ GPT ì •êµí™” ì‹¤íŒ¨]: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWyPv8MJ1T5I"
   },
   "outputs": [],
   "source": [
    "# âœ… íŠ¹ìˆ˜ê¸°í˜¸ ìœ„ì¹˜ ì ê²€ ë° ë³´ì • ìš”ì²­\n",
    "def verify_special_symbols(original_image: Image.Image, restored_text: str) -> str:\n",
    "    base64_img = image_to_base64(original_image)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "      ë„ˆëŠ” ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ì˜ ì§€ë¬¸ OCR ë³µì› ì „ë¬¸ê°€ì•¼.\n",
    "\n",
    "      ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ ì§€ë¬¸ê³¼ ì›ë³¸ ì´ë¯¸ì§€ì•¼. ë„ˆëŠ” ì´ ë‘ ì •ë³´ë¥¼ ë¹„êµí•´ì„œ ë‹¤ìŒê³¼ ê°™ì´ OCR ê²°ê³¼ë¥¼ ì •í™•í•˜ê²Œ ìˆ˜ì •í•´ì•¼ í•´.\n",
    "      ì¶”ì¶œí•œ ì§€ë¬¸ì˜ íŠ¹ìˆ˜ê¸°í˜¸(ã‰ , ã‰¡, ã‰¢, ã‰£, ã‰¤, â“, â“‘, â“’, â““, â“” ë“±)ê°€ ì›ë³¸ ì´ë¯¸ì§€ì˜ íŠ¹ìˆ˜ê¸°í˜¸ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ì„œ ìˆ˜ì •í•´ì¤˜.\n",
    "\n",
    "      ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³´ê³ \n",
    "      - ë¬¸ì¥ ì• ê¸°í˜¸ê°€ ì´ë¯¸ì§€ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ ,\n",
    "      - ì˜ëª»ëœ ê¸°í˜¸ëŠ” ì˜¬ë°”ë¥¸ íŠ¹ìˆ˜ê¸°í˜¸ë¡œ ìˆ˜ì •í•´.\n",
    "      - ì´ë¯¸ì§€ì—ëŠ” íŠ¹ìˆ˜ê¸°í˜¸ê°€ ì—†ëŠ”ë° í…ìŠ¤íŠ¸ì—ëŠ” ìˆëŠ” ê²½ìš°ëŠ” íŠ¹ìˆ˜ê¸°í˜¸ë¥¼ ì‚­ì œí•´ì¤˜.\n",
    "      - **ì¶”ì¶œí•œ ì§€ë¬¸ì˜ íŠ¹ìˆ˜ê¸°í˜¸ ë’¤ì— ê´„í˜¸'('ê°€ ì—†ë‹¤ë©´ ì´ë¯¸ì§€ì—ì„œ ë°‘ì¤„ë¡œ ê°•ì¡°ëœ ë¶€ë¶„ì„ ì°¾ì•„ì„œ ê´„í˜¸ë¡œ ê°ì‹¸ì„œ ì§€ë¬¸ì„ ìˆ˜ì •í•´ì¤˜.**\n",
    "\n",
    "      âš ï¸ â‘ , â‘¡, â‘¢, â‘£, â‘¤ ì´ëŸ° ì›í˜• ìˆ«ì íŠ¹ìˆ˜ê¸°í˜¸ëŠ” ì§€ë¬¸ì— ìˆì„ ìˆ˜ ì—†ì–´ ë°˜ë“œì‹œ ë‹¤ì‹œ ì˜¬ë°”ë¥¸ íŠ¹ìˆ˜ê¸°í˜¸ë¡œ ìˆ˜ì •í•´ì¤˜.\n",
    "      âš ï¸ ë™ì¼í•œ íŠ¹ìˆ˜ê¸°í˜¸ê°€ ë˜ ë‚˜ì˜¬ ìˆ˜ ì—†ì–´ ë‹¤ì‹œ ì˜¬ë°”ë¥¸ íŠ¹ìˆ˜ê¸°í˜¸ë¡œ ìˆ˜ì •í•´ì¤˜.\n",
    "      âš ï¸ ë°˜ë“œì‹œ íŠ¹ìˆ˜ê¸°í˜¸ ë’¤ì—ëŠ” ë°‘ì¤„ë¡œ ê°•ì¡°ëœ ë¶€ë¶„ì´ ê´„í˜¸'()'ë¡œ ë°˜ë“œì‹œ ê°ì‹¸ì ¸ ìˆì–´ì•¼í•´.\n",
    "      âš ï¸ ì¶”ì¶œí•œ ì§€ë¬¸ì˜ íŠ¹ìˆ˜ê¸°í˜¸ ë’¤ì— ê´„í˜¸ê°€ ì—†ë‹¤ë©´ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ íŠ¹ìˆ˜ê¸°í˜¸ ë’¤ì— ë‹¤ì‹œ ë°‘ì¤„ë¡œ ê°•ì¡°ëœ ë¶€ë¶„ì„ ë‹¤ì‹œ ì°¾ê³  ì§€ë¬¸ í…ìŠ¤íŠ¸ì— ê´„í˜¸'()'ë¥¼ ì¶”ê°€í•´ì¤˜.\n",
    "      âš ï¸ ì´ë¯¸ì§€ ê¸°í˜¸ ìœ„ì¹˜ë¥¼ ê¼­ í™•ì¸í•´ íŒë‹¨í•˜ê³ ,\n",
    "      âš ï¸ ì¶œë ¥ì€ ë°˜ë“œì‹œ ì§€ë¬¸ ì „ì²´ë¥¼ ì¶œë ¥í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": f\"ë³µì›ëœ ì§€ë¬¸ ì¼ë¶€:\\n{restored_text.strip()}\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\n",
    "                            \"url\": base64_img,\n",
    "                            \"detail\": \"high\"\n",
    "                        }}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=16000\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[âŒ GPT ê¸°í˜¸ ê²€í†  ì‹¤íŒ¨]: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv2z1cW2FvKP"
   },
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ìš°ì¸¡ ì§€ë¬¸ ë²”ìœ„ í‘œì‹œ\n",
    "def insert_passage_brackets_with_gpt(image: Image.Image, ocr_text: str) -> str:\n",
    "    base64_img = image_to_base64(image)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ì˜ ì§€ë¬¸ OCR ë³µì› ì „ë¬¸ê°€ì•¼.\n",
    "\n",
    "    ë‹¤ìŒì€ OCRë¡œ ì¶”ì¶œí•œ ì§€ë¬¸ê³¼ ì›ë³¸ ì´ë¯¸ì§€ì•¼.\n",
    "    ì›ë³¸ ì´ë¯¸ì§€ì˜ **ì¢Œì¸¡ í˜¹ì€ ìš°ì¸¡ì— [A], [B], [C] ë“±ì˜ í‘œì‹œì™€ í•¨ê»˜ íŠ¹ì • ì§€ë¬¸ ë²”ìœ„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„ ë“¤ì´ ìˆëŠ” ê²½ìš°ê°€ ìˆì–´.**\n",
    "    ì´ ì‹œê°ì  ì •ë³´ëŠ” ì–´ë–¤ ì§€ë¬¸ êµ¬ê°„ì´ ë¬¸ì œ í’€ì´ì—ì„œ ì¤‘ìš”í•œì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” ë‹¨ì„œì•¼.\n",
    "\n",
    "    ğŸ” ë„ˆì˜ ì„ë¬´ëŠ” ë‹¤ìŒê³¼ ê°™ì•„:\n",
    "\n",
    "    1. ì§€ë¬¸ ì´ë¯¸ì§€ì˜ ë§¨ ì™¼ìª½ê³¼ ë§¨ ì˜¤ë¥¸ìª½ì„ ì˜ ì‚´í´ë³´ê³ ,\n",
    "      íŠ¹ì • ì§€ë¬¸ ë²”ìœ„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„ ê³¼ í•¨ê»˜ [A], [B], [C] ë“±ì´ ì§€ë¬¸ ë‚´ **ì–´ë””ì„œë¶€í„° ì–´ë””ê¹Œì§€ë¥¼ ê°€ë¦¬í‚¤ëŠ”ì§€** íŒë‹¨í•´.\n",
    "        - ê° ë²”ìœ„ëŠ” ë°˜ë“œì‹œ **1ì¤„ ì´ìƒ**ì´ ë˜ë„ë¡ í•˜ê³ , **ë¬¸ì¥ì´ ëŠê¸°ì§€ ì•Šê²Œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨**í•´ì•¼ í•´.\n",
    "        - ë¬¸ì¥ì˜ ì‹œì‘ì´ë‚˜ ëì´ ì˜ë¦¬ì§€ ì•Šë„ë¡, ì§€ë¬¸ íë¦„ì— ë§ê²Œ í•´ë‹¹ **ì‹œì‘ ì¤„ê³¼ ë ì¤„ ì „ì²´ë¥¼ í¬í•¨**í•´ì•¼ í•´.\n",
    "\n",
    "    2. ë§Œì•½ íŠ¹ì • ì§€ë¬¸ ë²”ìœ„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„ ì´ ìˆë‹¤ë©´, íŒë‹¨ëœ ë²”ìœ„ë¥¼ ì§€ë¬¸ ì¤‘ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜ ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ `[A]{}`ë¡œ ê°ì‹¸ ê°•ì¡°í•´ì¤˜:\n",
    "        ...\n",
    "        [A] {\n",
    "            (í•´ë‹¹ ë²”ìœ„ ì‹œì‘ ì¤„)\n",
    "            ...\n",
    "            (í•´ë‹¹ ë²”ìœ„ ë ì¤„)\n",
    "        }\n",
    "        ...\n",
    "\n",
    "    âš ï¸ ìœ ì˜ì‚¬í•­:\n",
    "    - ì¤„ ë‹¨ìœ„ë¡œ íŒë‹¨í•˜ë˜, ì˜ë¯¸ ë‹¨ìœ„(ë¬¸ì¥ êµ¬ì¡°)ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•´ì•¼ í•´.\n",
    "    - íŠ¹ì • ì§€ë¬¸ ë²”ìœ„ì˜ ì‹œì‘ê³¼ ë ìœ„ì¹˜ëŠ” ì´ë¯¸ì§€ ì˜¤ë¥¸ìª½ì˜ ì„ ê³¼ ì‹œê°ì ìœ¼ë¡œ ì •ë ¬ëœ ì§€ë¬¸ ì¤„ì„ ì°¾ì•„ íŒë‹¨í•´ì•¼ í•´.\n",
    "    - ì¤„ë°”ê¿ˆ, ê³µë°±, ê´„í˜¸, íŠ¹ìˆ˜ê¸°í˜¸ ë“±ì€ OCR í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": f\"OCR ê²°ê³¼:\\n{ocr_text.strip()}\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\n",
    "                            \"url\": base64_img,\n",
    "                            \"detail\": \"high\"\n",
    "                        }}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=16000\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[âŒ GPT ì§€ë¬¸ ë²”ìœ„ ì‚½ì… ì‹¤íŒ¨]: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4VPhEUEb5Ki"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def run_split_pipeline(image_path: str, parts: int = 4):\n",
    "    print(\"ğŸ“‚ ì´ë¯¸ì§€ ë¡œë”© ì¤‘...\")\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # 1. ì´ë¯¸ì§€ ìˆ˜ì§ ë¶„í• \n",
    "    print(f\"ğŸ”€ ì´ë¯¸ì§€ {parts}ë“±ë¶„ ì¤‘...\")\n",
    "    split_images = split_image_vertically(image, parts=parts)\n",
    "\n",
    "    # 2. ê° ë¶„í•  ì´ë¯¸ì§€ OCR\n",
    "    ocr_parts = []\n",
    "    for idx, part_img in enumerate(split_images):\n",
    "        print(f\"ğŸ” [{idx + 1}/{parts}] ë¶„í•  ì´ë¯¸ì§€ OCR ì¤‘...\")\n",
    "        part_text = gpt_ocr_text(part_img)\n",
    "        ocr_parts.append(part_text)\n",
    "\n",
    "    # 3. OCR ê²°ê³¼ ë³‘í•©\n",
    "    combined_ocr = \"\\n\".join(ocr_parts).strip()\n",
    "\n",
    "    # 4. GPTë¡œ ì •êµí™”(íŠ¹ìˆ˜ê¸°í˜¸&ê´„í˜¸ ì‚½ì…)\n",
    "    print(\"ğŸ”§ GPT ì •êµí™” ë‹¨ê³„ ì§„í–‰ ì¤‘...\")\n",
    "    refined_text = refine_text_with_gpt(image, combined_ocr)\n",
    "\n",
    "    # 5. íŠ¹ìˆ˜ê¸°í˜¸ ìœ„ì¹˜ ê²€í†  ë° ë³´ì • => ì„±ê³µ\n",
    "    print(\"ğŸ§  íŠ¹ìˆ˜ê¸°í˜¸ ìœ„ì¹˜ ê²€í†  ë° ë³´ì • ì¤‘...\")\n",
    "    symbol_corrected_text = verify_special_symbols(image, refined_text)\n",
    "\n",
    "    # 6. ì´ë¯¸ì§€ ìš°ì¸¡ ì§€ë¬¸ ë²”ìœ„ í‘œì‹œ\n",
    "    print(\"ğŸ—‚ï¸ GPT ì§€ë¬¸ ë²”ìœ„ í‘œì‹œ([A], [B] ë“±) ì‚½ì… ì¤‘...\")\n",
    "    final_result = insert_passage_brackets_with_gpt(image, symbol_corrected_text)\n",
    "\n",
    "    return final_result.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itQlrdn8GuoV"
   },
   "source": [
    "### **ë¬¸ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFPHxj62GyBd"
   },
   "outputs": [],
   "source": [
    "def extract_question(question_path):\n",
    "    import mimetypes\n",
    "\n",
    "    # íŒŒì¼ í™•ì¥ìì— ë§ê²Œ MIME íƒ€ì… ì¶”ì •\n",
    "    mime_type, _ = mimetypes.guess_type(question_path)\n",
    "    if not mime_type:\n",
    "        mime_type = \"image/png\"  # ê¸°ë³¸ê°’ fallback\n",
    "\n",
    "    with open(question_path, \"rb\") as f:\n",
    "        base64_img = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    image_url = f\"data:{mime_type};base64,{base64_img}\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •í™•í•˜ê²Œ ë³µì›í•˜ëŠ” OCR ëª¨ë¸ì´ì•¼.\n",
    "    ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ë³´ê³  **ë¬¸ì œì˜ í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶”ì¶œ**í•´ì•¼ í•´.\n",
    "\n",
    "    ì…ë ¥ ì´ë¯¸ì§€ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë  ìˆ˜ ìˆì–´:\n",
    "    - ë¬¸í•™ ë¬¸ì œì˜ ì§ˆë¬¸ ë¬¸ì¥\n",
    "    - â‘ ~â‘¤ ë³´ê¸° ì„ íƒì§€\n",
    "    - ê²½ìš°ì— ë”°ë¼, ì§ˆë¬¸ ë¬¸ì¥ **ë’¤ì—** ì œì‹œë˜ëŠ” '<ë³´ê¸°>' ë¬¸ì¥\n",
    "\n",
    "    ğŸ”¹ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì¶œë ¥ ê·œì¹™:\n",
    "\n",
    "    1. ì´ë¯¸ì§€ì— '<ë³´ê¸°>'ê°€ ì¡´ì¬í•˜ë©´, ì§ˆë¬¸ ë¬¸ì¥ **ë’¤ì—** <ë³´ê¸°> ì „ì²´ ë‚´ìš©ì„ ì •í™•íˆ í¬í•¨í•´ì•¼ í•´.\n",
    "    2. <ë³´ê¸°>ê°€ ì—†ë‹¤ë©´, ì§ˆë¬¸ ë¬¸ì¥ ë‹¤ìŒì— ë°”ë¡œ ì„ íƒì§€ë¥¼ ì¶œë ¥í•´.\n",
    "    3. ì„ íƒì§€ëŠ” í•­ìƒ â‘ ~â‘¤ ëª¨ë‘ ë¹ ì§ì—†ì´ ì¶œë ¥í•  ê²ƒ.\n",
    "    4. ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ì•„ì•¼ í•´:\n",
    "\n",
    "    (ì§ˆë¬¸ ë¬¸ì¥)\n",
    "\n",
    "    <ë³´ê¸°>\n",
    "    (ë³´ê¸° ë‚´ìš©)\n",
    "\n",
    "    â‘  ...\n",
    "    â‘¡ ...\n",
    "    â‘¢ ...\n",
    "    â‘£ ...\n",
    "    â‘¤ ...\n",
    "\n",
    "    â—ì£¼ì˜:\n",
    "    - <ë³´ê¸°>ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ê³ , **ì§ˆë¬¸ ë’¤ì— ìœ„ì¹˜**ì‹œì¼œì•¼ í•´.\n",
    "    - ì¤„ë°”ê¿ˆ, ê¸°í˜¸, ë¬¸ì¥ë¶€í˜¸ ë“±ì€ ìµœëŒ€í•œ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë³µì›í•´.\n",
    "    - ì ˆëŒ€ ì„¤ëª…, í•´ì„¤, ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë“± **ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆ**.\n",
    "    - ì˜¤ì§ ì´ë¯¸ì§€ ì† ë¬¸ì œ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": image_url\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1500,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zi1rIhzotly"
   },
   "source": [
    "# **<ë‹µë³€,í•´ì„¤ ëª¨ë¸>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-YnZ-dIo4KN",
    "outputId": "c8427013-083a-4836-ed1e-c7de00e66956"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-13-250192327.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# ê°œë… ì„¤ëª… ì²´ì¸\n",
    "concept_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë„ˆëŠ” í•œêµ­ì˜ ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜ì˜ êµ­ì–´ ê³¼ëª© ì¤‘ ë¬¸í•™ì˜ ê°œë…ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ëŠ” íŠœí„°ì•¼. ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•´ì¤˜.\n",
    "\n",
    "ì§ˆë¬¸:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "concept_chain = concept_prompt | llm | StrOutputParser()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "\n",
    "# <1. ê°œë… ì„¤ëª… chain>\n",
    "concept_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë„ˆëŠ” í•œêµ­ì˜ ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜ì˜ êµ­ì–´ ê³¼ëª© ì¤‘ ë¬¸í•™ì˜ ê°œë…ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ëŠ” íŠœí„°ì•¼. ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•´ì¤˜.\n",
    "\n",
    "ì§ˆë¬¸:\n",
    "{question}\n",
    "\"\"\")\n",
    "concept_chain = concept_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# ë¬¸ì œ ê¸°ë°˜ QA ì²´ì¸ìš© í”„ë¡¬í”„íŠ¸\n",
    "qa_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ í•œêµ­ ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ ì „ë¬¸ íŠœí„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒì€ ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ ê°ê´€ì‹ ë¬¸ì œì…ë‹ˆë‹¤. â‘ , â‘¡, â‘¢, â‘£, â‘¤ ì¤‘ í•˜ë‚˜ë¥¼ ê³ ë¥´ëŠ” ê°ê´€ì‹ ë¬¸ì œì´ë©°,\n",
    "ì •ë‹µì€ ë°˜ë“œì‹œ ì§€ë¬¸ ë° <ë³´ê¸°>ì˜ ì •í™•í•œ ë¶„ì„ì— ê·¼ê±°í•´ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸŸ¨ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ë¶„ì„ ê¸°ì¤€:\n",
    "\n",
    "1. ì§€ë¬¸ ë¶„ì„ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨í•˜ë©°, **ì„ íƒì§€ì˜ ë‚´ìš©ì´ ì§€ë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€** ì—„ë°€íˆ ê²€í† í•˜ì„¸ìš”.\n",
    "2. ë¬¸ì œì— <ë³´ê¸°>ê°€ ìˆë‹¤ë©´, <ë³´ê¸°> ì† ì„¤ëª…(êµ¬ì¡°, ì‹œì , í‘œí˜„, ì¸ë¬¼ í•´ì„ ë“±)ì„ **ì§€ë¬¸ì— ì–´ë–»ê²Œ ì ìš©í–ˆëŠ”ì§€** êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.\n",
    "3. **ì„œìˆ  ë°©ì‹, ì¸ë¬¼ ì‹¬ë¦¬ í‘œí˜„, ë¬¸ì²´, ì‹œì  ë³€í™”, ì§€ì‹œ í‘œí˜„, ë³‘ë ¬ êµ¬ì¡°** ë“±ì€ ì„œìˆ ìƒÂ·í‘œí˜„ìƒ íŠ¹ì§• ë¬¸ì œì—ì„œ í•µì‹¬ ê·¼ê±°ì…ë‹ˆë‹¤.\n",
    "4. ì°¸ê³  ìë£ŒëŠ” ë°˜ë“œì‹œ ë³´ì¡°ì  ìš©ë„ë¡œë§Œ í™œìš©í•©ë‹ˆë‹¤. ì ˆëŒ€ ì§€ë¬¸ì„ ë®ì–´ì“°ê±°ë‚˜ ëŒ€ì²´í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ“Œ ë‹µë³€ í˜•ì‹:\n",
    "\n",
    "[ì •ë‹µ]\n",
    "- (â‘ , â‘¡, â‘¢, â‘£, â‘¤ ì¤‘ í•˜ë‚˜)\n",
    "\n",
    "[í•´ì„¤]\n",
    "- ë¬¸ì œì—ì„œ ìš”êµ¬í•œ í•µì‹¬ ìš”ì†Œ(ì˜ˆ: í‘œí˜„ ë°©ì‹, êµ¬ì¡°, ì‹œì  ë“±)ì— ë”°ë¼ ì™œ ì •ë‹µì¸ì§€ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "- ì§€ë¬¸ ë° <ë³´ê¸°>ì˜ ë¬¸ì¥ì„ **ì§ì ‘ ì¸ìš©**í•˜ì—¬ ëª…í™•í•œ íŒë‹¨ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.\n",
    "- ë‚˜ë¨¸ì§€ ì˜¤ë‹µ ì„ íƒì§€ë“¤ì€ ê°ê° ì™œ í‹€ë ¸ëŠ”ì§€ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "\n",
    "ğŸ“– [ì§€ë¬¸]\n",
    "{context}\n",
    "\n",
    "ğŸ“š [ì°¸ê³  ìë£Œ] â€” í•„ìš” ì‹œë§Œ ì‚¬ìš© (retriever ì œê³µ):\n",
    "{reference}\n",
    "\n",
    "ğŸ™‹â€â™‚ï¸ [ë¬¸ì œ ë° <ë³´ê¸°>]\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "def format_with_retrieved_docs(inputs):\n",
    "    question = inputs[\"question\"]\n",
    "    context = inputs[\"context\"]\n",
    "\n",
    "    # ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (contextì™€ question ëª¨ë‘ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰)\n",
    "    retrieved_docs = retriever_literature_answer.get_relevant_documents(f\"{context}\\n\\n{question}\")\n",
    "    retrieved_context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    return {\n",
    "        \"context\": context,           # ì§€ë¬¸ ë° <ë³´ê¸°>\n",
    "        \"reference\": retrieved_context,  # ë³´ì¡° ìë£Œ\n",
    "        \"question\": question\n",
    "    }\n",
    "\n",
    "# <2. ë‹µë³€, í•´ì„¤ QA ì²´ì¸>: ë¬¸í•­ ì§€ë¬¸ ì¤‘ì‹¬ + retrieverì—ì„œ ê²€ìƒ‰í•œ ë‚´ìš© ì°¸ê³ \n",
    "rag_qa_chain = (\n",
    "    RunnableLambda(format_with_retrieved_docs)\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# <ë¬¸ì œ vs ê°œë… ë¶„ë¥˜ í•¨ìˆ˜>\n",
    "def is_problem_question(question: str) -> bool:\n",
    "    classification_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬¸í•™ ê°œë… ì§ˆë¬¸ì¸ì§€, ì§€ë¬¸ ê¸°ë°˜ ë¬¸ì œì¸ì§€ íŒë³„í•´ì¤˜. 'ê°œë…' ë˜ëŠ” 'ë¬¸ì œ' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•´.\n",
    "\n",
    "ì§ˆë¬¸:\n",
    "{question}\n",
    "\"\"\")\n",
    "    chain = classification_prompt | llm | StrOutputParser()\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    return \"ë¬¸ì œ\" in result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-q1hatZXAq_"
   },
   "outputs": [],
   "source": [
    "# <ìµœì¢… ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜>\n",
    "def tutor_response(question: str, passage: str = None) -> str:\n",
    "    if is_problem_question(question):\n",
    "        if not passage:\n",
    "            print(\"â— ì˜¤ë¥˜: ë¬¸í•™ ë¬¸ì œ í’€ì´ì—ëŠ” ì§€ë¬¸(passage)ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "            return \"[â— ì˜¤ë¥˜: ì§€ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤]\"\n",
    "\n",
    "        print(\"ğŸ“˜ [ë¬¸ì œì— ëŒ€í•œ ì •ë‹µ ë° í•´ì„¤]\")\n",
    "        response = rag_qa_chain.invoke({\n",
    "            \"context\": passage,\n",
    "            \"question\": question\n",
    "        })\n",
    "        return response\n",
    "    else:\n",
    "        print(\"ğŸ“˜ [ë¬¸í•™ ê°œë… ì„¤ëª…]\")\n",
    "        response = concept_chain.invoke({\"question\": question})\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVQauqBIqB1p"
   },
   "source": [
    "# **<ìœ ì‚¬ ê¸°ì¶œë¬¸ì œ ì¶”ì²œ ëª¨ë¸>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ptrf9sjqGFS"
   },
   "outputs": [],
   "source": [
    "# <ì‚¬ìš©ì ì§ˆë¬¸ì˜ GPT íƒœê¹…>\n",
    "def get_tags_from_gpt(query):\n",
    "    prompt = f\"\"\"\n",
    "            ë‹¤ìŒ ë¬¸í•™ ì§€ë¬¸ê³¼ ë¬¸ì œë¥¼ ì½ê³  ì•„ë˜ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "            ğŸ“š ì…ë ¥ ì •ë³´\n",
    "            (ì§€ë¬¸&ë¬¸ì œ)\n",
    "            {query}\n",
    "\n",
    "            ğŸ§© ë³µí•©/ë‹¨ì¼ íŒë‹¨ ê¸°ì¤€:\n",
    "            - ì§€ë¬¸ì´ 2ê°œ ì´ìƒì´ë©´ ë°˜ë“œì‹œ \"ë³µí•©\"ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n",
    "            - ë¬¸ì œì—ì„œ 'ê³µí†µì ', 'ë¹„êµ', 'ë‹¤ìŒ ê¸€ë“¤', '(ê°€)ì™€ (ë‚˜)'ë¼ëŠ” í‘œí˜„ì´ ë“±ì¥í•˜ë©´ ë°˜ë“œì‹œ \"ë³µí•©\"ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n",
    "            - ìœ„ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ ì¶©ì¡±í•˜ë©´ ë°˜ë“œì‹œ \"ë³µí•©\"ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n",
    "            - ì§€ë¬¸ì´ 1ê°œì´ê±°ë‚˜ ì§€ë¬¸ ì—¬ëŸ¬ê°œ ì¤‘ì—ì„œ ë¬¸ì œì—ì„œ í•œ íŠ¹ì • ì§€ë¬¸ë§Œ ë¬»ëŠ” ê²½ìš°ì—ë§Œ \"ë‹¨ì¼\"ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n",
    "            âš ï¸ ë³µí•©/ë‹¨ì¼ ë¶„ë¥˜ëŠ” ì ˆëŒ€ í‹€ë¦¬ë©´ ì•ˆ ë©ë‹ˆë‹¤. ë°˜ë“œì‹œ ì£¼ì˜í•˜ì„¸ìš”.\n",
    "\n",
    "            ğŸ§  ë¬¸ì œ ìœ í˜• ë¶„ë¥˜ ê¸°ì¤€ (ì§€ë¬¸ ì¥ë¥´ë³„ë¡œ ì•„ë˜ ì¤‘ í•˜ë‚˜ ì„ íƒ):\n",
    "            - í˜„ëŒ€ì‹œ:\n",
    "              - ë‚´ìš© ì´í•´: ì‹œì  ìƒí™©, ì£¼ì œ, ì •ì„œ ë° íƒœë„ ë“± íŒŒì•…\n",
    "              - ì •ì„œ ë° íƒœë„ íŒŒì•…: í™”ìì˜ ì‹¬ë¦¬ì™€ íƒœë„ íë¦„ ì´í•´\n",
    "              - í‘œí˜„ ë°©ì‹ ë¶„ì„: ë¹„ìœ , ìƒì§•, ë°˜ë³µ, ì„¤ì˜ ë“±\n",
    "              - ì‹œì–´ í•´ì„: ê°œë³„ ì‹œì–´ ë˜ëŠ” í‘œí˜„ì˜ ìƒì§•/ì¤‘ì˜ì  ì˜ë¯¸ í•´ì„\n",
    "              - ìƒì§•/ë¹„ìœ  í•´ì„: ì¤‘ì‹¬ ì´ë¯¸ì§€ë‚˜ ìƒì§• êµ¬ì¡° í•´ì„\n",
    "\n",
    "            - ê³ ì „ ì‹œê°€:\n",
    "              - ë‚´ìš© ì´í•´: ì „ì²´ ì˜ë¯¸, ì‘í’ˆ íë¦„, ì •ì„œ ì´í•´\n",
    "              - ì •ì„œ íŒŒì•…: ì„ì— ëŒ€í•œ ë§ˆìŒ, ìì—°/í˜„ì‹¤ ì¸ì‹\n",
    "              - í‘œí˜„ ê¸°ë²• ë¶„ì„: ê³ ì „ì  ìˆ˜ì‚¬ ê¸°ë²• ë¶„ì„ (ì˜íƒ„, ëŒ€ì¡°, ê³¼ì¥ ë“±)\n",
    "              - ì„-í™”ì ê´€ê³„ ì´í•´: êµìˆ /ì„œì • ì‹œê°€ì—ì„œì˜ ê´€ê³„ ë§¥ë½\n",
    "              - ë³€ì‹ /í™˜ìƒ í‘œí˜„ í•´ì„: ì‹ í™”/í™˜ìƒì  ìš”ì†Œ í•´ì„\n",
    "\n",
    "            - í˜„ëŒ€ ì†Œì„¤:\n",
    "              - ì‚¬ê±´ íë¦„ íŒŒì•…: ì¤„ê±°ë¦¬ ë° ì£¼ìš” ì‚¬ê±´ íë¦„ ì´í•´\n",
    "              - ì¸ë¬¼ ì‹¬ë¦¬ ì´í•´: ì¸ë¬¼ì˜ ì„±ê²©, ë‚´ì  ì‹¬ë¦¬, ê´€ê³„ í•´ì„\n",
    "              - ì‹œì  ë° ì„œìˆ  ë°©ì‹ ë¶„ì„: ì„œìˆ ì, ì‹œì , ë¬˜ì‚¬ ë°©ì‹ ë¶„ì„\n",
    "              - ì£¼ì œ/ì‘ê°€ ì˜ë„ íŒŒì•…: ì¤‘ì‹¬ ì£¼ì œ, ì£¼ì œì˜ì‹ ë¶„ì„\n",
    "              - ê³µê°„/ë°°ê²½ ì˜ë¯¸ ë¶„ì„: ë°°ê²½ì´ ê°€ì§€ëŠ” ìƒì§•ì  ì˜ë¯¸ í•´ì„\n",
    "\n",
    "            - ê³ ì „ ì†Œì„¤:\n",
    "              - ë‚´ìš© ì´í•´: ì¤„ê±°ë¦¬, ì‚¬ê±´ êµ¬ì¡° íŒŒì•…\n",
    "              - ì¸ë¬¼ ì‹¬ë¦¬ ë° ìš´ëª… íŒŒì•…: ì£¼ìš” ì¸ë¬¼ì˜ ì„±ê²©ê³¼ ìš´ëª…\n",
    "              - ìƒì§• ì¥ì¹˜ í•´ì„: ê¿ˆ, ì „ê¸°, ìì—° ìš”ì†Œ ë“± ìƒì§• êµ¬ì¡° í•´ì„\n",
    "              - ê¶Œì„ ì§•ì•…ì  ê´€ì  ë¶„ì„: ì¸ê³¼ì  ì„¸ê³„ê´€, ë„ë•ì  êµí›ˆ í•´ì„\n",
    "              - ì„œì‚¬ êµ¬ì¡° ë¶„ì„: ë„ì…-ì „ê°œ-ìœ„ê¸°-ì ˆì •-ê²°ë§ì˜ êµ¬ì¡°\n",
    "\n",
    "            - ê·¹/ìˆ˜í•„:\n",
    "              - ë‚´ìš© ì´í•´: ìƒí™©, ëŒ€ì‚¬, ì‚¬ê±´ì˜ íë¦„ ì´í•´\n",
    "              - í‘œí˜„ íŠ¹ì„± ë¶„ì„: ëŒ€ì‚¬, í•´ì„¤, ì¥ë©´ êµ¬ì„±ì˜ íŠ¹ì§•\n",
    "              - ì„œìˆ ìì˜ ê°œì… íŒŒì•…: ìˆ˜í•„/ê·¹ ì¤‘ ì„œìˆ ìì˜ ìœ„ì¹˜ ë° ì—­í• \n",
    "              - ì£¼ì œ ë° êµí›ˆ ë„ì¶œ: ì¤‘ì‹¬ ì£¼ì œ ë° ì‚¶ì— ì£¼ëŠ” êµí›ˆ í•´ì„\n",
    "\n",
    "            âœ’ï¸ ì§€ë¬¸ ì œëª© ë° ì‘ê°€ ì¶”ì¶œ ê¸°ì¤€:\n",
    "            - ì¼ë°˜ì ìœ¼ë¡œ ê° ì§€ë¬¸ ëì— ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í‘œê¸°ë¨:\n",
    "              `- ê¹€ìˆ˜ì˜ , ï½¢ê·¸ ë°©ì„ ìƒê°í•˜ë©°ï½£ -`\n",
    "              â†’ ì‘ê°€: \"ê¹€ìˆ˜ì˜\", ì œëª©: \"ê·¸ ë°©ì„ ìƒê°í•˜ë©°\"\n",
    "            - ë³µí•© ì§€ë¬¸ì¼ ê²½ìš°:\n",
    "              - \"ì§€ë¬¸ ì œëª©\": [\"ì œëª©1\", \"ì œëª©2\", ...]\n",
    "              - \"ì§€ë¬¸ ì‘ê°€\": [\"ì‘ê°€1\", \"ì‘ê°€2\", ...]\n",
    "              - ì‘ì ë¯¸ìƒì¼ ê²½ìš° \"ì‘ì ë¯¸ìƒ\"ìœ¼ë¡œ í‘œê¸°\n",
    "              âš ï¸ ì œëª© ë˜ëŠ” ì‘ê°€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°:\n",
    "              - ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•˜ì„¸ìš”.\n",
    "              - ì§€ë¬¸ ì œëª©: \"ì§€ë¬¸ ì œëª© ì—†ìŒ\"\n",
    "              - ì§€ë¬¸ ì‘ê°€: \"ì‘ì ë¯¸ìƒ\"\n",
    "              - ë³µí•© ì§€ë¬¸ì¼ ê²½ìš°: [\"ì§€ë¬¸ ì œëª© ì—†ìŒ\", \"ì§€ë¬¸ ì œëª© ì—†ìŒ\"], [\"ì‘ì ë¯¸ìƒ\", \"ì‘ì ë¯¸ìƒ\"]\n",
    "\n",
    "            ğŸ“Œ ì¶œë ¥ í˜•ì‹ (ëª¨ë‘ í¬í•¨):\n",
    "            - type: ë°˜ë“œì‹œ \"ë¬¸í•™\"\n",
    "            - ì§€ë¬¸ ì œëª©: ë¬¸ìì—´ ë˜ëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸\n",
    "            - ì§€ë¬¸ ì¥ë¥´: ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ (ê°ˆë˜ ë³µí•©ì´ë©´ ë¦¬ìŠ¤íŠ¸)\n",
    "            - ì§€ë¬¸ ì‘ê°€: ë¬¸ìì—´ ë˜ëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸\n",
    "            - ë³µí•©/ë‹¨ì¼: \"ë³µí•©\" ë˜ëŠ” \"ë‹¨ì¼\"\n",
    "            - ë¬¸ì œ ìœ í˜•: ìœ„ ê¸°ì¤€ ì¤‘ ì ì ˆí•œ ê²ƒ í•˜ë‚˜\n",
    "\n",
    "            ğŸ“Œ ì¶œë ¥ ì˜ˆì‹œ:\n",
    "\n",
    "            [ì§€ë¬¸ 1ê°œ ì˜ˆì‹œ]\n",
    "            {{\n",
    "              \"type\": \"ë¬¸í•™\",\n",
    "              \"ì§€ë¬¸ ì œëª©\": \"ìˆ™í–¥ì „\",\n",
    "              \"ì§€ë¬¸ ì¥ë¥´\": \"ê³ ì „ ì†Œì„¤\",\n",
    "              \"ì§€ë¬¸ ì‘ê°€\": \"ì‘ì ë¯¸ìƒ\",\n",
    "              \"ë³µí•©/ë‹¨ì¼\": \"ë‹¨ì¼\",\n",
    "              \"ë¬¸ì œ ìœ í˜•\": \"ì¸ë¬¼ ì‹¬ë¦¬ ë° ìš´ëª… íŒŒì•…\"\n",
    "            }}\n",
    "\n",
    "            [ì§€ë¬¸ ì—¬ëŸ¬ê°œ ì˜ˆì‹œ]\n",
    "            {{\n",
    "              \"type\": \"ë¬¸í•™\",\n",
    "              \"ì§€ë¬¸ ì œëª©\": [\"ë³„ì‚¬ë¯¸ì¸ê³¡\", \"ì œëª© ì—†ìŒ\", \"ë°±ìì¦ì •ë¶€ì¸ë°•ì”¨ë¬˜ì§€ëª…\"],\n",
    "              \"ì§€ë¬¸ ì¥ë¥´\": [\"ê³ ì „ ì‹œê°€\", \"ê³ ì „ ì‹œê°€\", \"ê³ ì „ ì‚°ë¬¸\"],\n",
    "              \"ì§€ë¬¸ ì‘ê°€\": [\"ê¹€ì¶˜íƒ\", \"ì´ì •ë³´\", \"ë°•ì§€ì›\"],\n",
    "              \"ë³µí•©/ë‹¨ì¼\": \"ë³µí•©\",\n",
    "              \"ë¬¸ì œ ìœ í˜•\": \"ì •ì„œ íŒŒì•…\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸í•™ ì „ë¬¸ íƒœê¹… ë„ìš°ë¯¸ì…ë‹ˆë‹¤. âš ï¸ ë°˜ë“œì‹œ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    # GPTê°€ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ìŒ€ ê²½ìš° ì œê±°\n",
    "    content = re.sub(r\"```json\\s*([\\s\\S]+?)\\s*```\", r\"\\1\", content)\n",
    "    content = re.sub(r\"```[\\s\\S]+?```\", \"\", content).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"âŒ GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨:\\n\", content)\n",
    "        return None\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# ğŸ”¸ GPT í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# ğŸ”¸ ë¬¸ì œ ì½”ë“œ ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_question_code(source_str):\n",
    "    if not source_str:\n",
    "        return None\n",
    "    source_str = source_str.replace(\"á„€á…®á†¨á„‹á…¥\", \"êµ­ì–´\")\n",
    "    match = re.search(r'(\\d{4}-(?:\\d{2}|ìˆ˜ëŠ¥)-êµ­ì–´_\\d+)$', source_str)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    all_matches = re.findall(r'(\\d{4}-(?:\\d{2}|ìˆ˜ëŠ¥)-êµ­ì–´_\\d+)', source_str)\n",
    "    if all_matches:\n",
    "        return all_matches[-1]\n",
    "    return source_str\n",
    "\n",
    "\n",
    "# ğŸ”¸ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ì— íƒœê·¸ ë³‘í•©\n",
    "def merge_tags_to_docs(docs, tag_dict):\n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get(\"source\")\n",
    "        code = extract_question_code(source)\n",
    "        if code and code in tag_dict:\n",
    "            doc.metadata[\"question_tags\"] = tag_dict[code]\n",
    "    return docs\n",
    "\n",
    "\n",
    "# ğŸ”¹ íƒœê·¸ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (ë¶€ë¶„ ì ìˆ˜ í¬í•¨)\n",
    "def tag_similarity_score(user_tags, doc_tags):\n",
    "    score = 0\n",
    "\n",
    "    # ë¬¸ì œ ìœ í˜• (4ì , ì™„ì „ ì¼ì¹˜ ì‹œ)\n",
    "    if user_tags.get(\"ë¬¸ì œ ìœ í˜•\") == doc_tags.get(\"ë¬¸ì œ ìœ í˜•\"):\n",
    "        score += 4\n",
    "\n",
    "    # ë³µí•©/ë‹¨ì¼ (2ì )\n",
    "    if user_tags.get(\"ë³µí•©/ë‹¨ì¼\") == doc_tags.get(\"ë³µí•©/ë‹¨ì¼\"):\n",
    "        score += 2\n",
    "\n",
    "    # ì§€ë¬¸ ì¥ë¥´ (ë¶€ë¶„ ì ìˆ˜ ë¶€ì—¬)\n",
    "    user_genre = user_tags.get(\"ì§€ë¬¸ ì¥ë¥´\")\n",
    "    doc_genre = doc_tags.get(\"ì§€ë¬¸ ì¥ë¥´\")\n",
    "\n",
    "    if user_genre == doc_genre:\n",
    "        score += 5\n",
    "    else:\n",
    "        # ë¹„ìŠ·í•œ ì¥ë¥´ ë¶€ë¶„ ì ìˆ˜\n",
    "        genre_similarities = [\n",
    "            (\"í˜„ëŒ€ì‹œ\", \"ê³ ì „ ì‹œê°€\"),\n",
    "            (\"ê³ ì „ ì‹œê°€\", \"í˜„ëŒ€ì‹œ\"),\n",
    "            (\"í˜„ëŒ€ ì†Œì„¤\", \"ê³ ì „ ì†Œì„¤\"),\n",
    "            (\"ê³ ì „ ì†Œì„¤\", \"í˜„ëŒ€ ì†Œì„¤\"),\n",
    "        ]\n",
    "        if (user_genre, doc_genre) in genre_similarities or (doc_genre, user_genre) in genre_similarities:\n",
    "            score += 2\n",
    "\n",
    "    # ì§€ë¬¸ ì œëª© (1ì )\n",
    "    user_title = user_tags.get(\"ì§€ë¬¸ ì œëª©\")\n",
    "    doc_title = doc_tags.get(\"ì§€ë¬¸ ì œëª©\")\n",
    "\n",
    "    if isinstance(user_title, list) and isinstance(doc_title, list):\n",
    "        if set(user_title) & set(doc_title):\n",
    "            score += 1\n",
    "    elif isinstance(user_title, list):\n",
    "        if doc_title in user_title:\n",
    "            score += 1\n",
    "    elif isinstance(doc_title, list):\n",
    "        if user_title in doc_title:\n",
    "            score += 1\n",
    "    else:\n",
    "        if user_title == doc_title:\n",
    "            score += 1\n",
    "\n",
    "    # ì§€ë¬¸ ì‘ê°€ (1ì )\n",
    "    user_name = user_tags.get(\"ì§€ë¬¸ ì‘ê°€\")\n",
    "    doc_name = doc_tags.get(\"ì§€ë¬¸ ì‘ê°€\")\n",
    "\n",
    "    if isinstance(user_name, list) and isinstance(doc_name, list):\n",
    "        if set(user_name) & set(doc_name):\n",
    "            score += 1\n",
    "    elif isinstance(user_name, list):\n",
    "        if doc_name in user_name:\n",
    "            score += 1\n",
    "    elif isinstance(doc_name, list):\n",
    "        if user_name in doc_name:\n",
    "            score += 1\n",
    "    else:\n",
    "        if user_name == doc_name:\n",
    "            score += 1\n",
    "\n",
    "    return score\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import Image as DisplayImage, display\n",
    "import streamlit as st\n",
    "\n",
    "# ì¶œì²˜ ì½”ë“œ ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_question_code(source_str):\n",
    "    if not source_str:\n",
    "        return None\n",
    "    source_str = unicodedata.normalize('NFC', source_str)\n",
    "    source_str = source_str.replace(\"á„€á…®á†¨á„‹á…¥\", \"êµ­ì–´\").replace(\"á„‰á…®á„‚á…³á†¼\", \"ìˆ˜ëŠ¥\")\n",
    "\n",
    "    # ì¶œì²˜ ì½”ë“œ ì •ê·œì‹ ì¶”ì¶œ (ëì— ìˆëŠ” ì½”ë“œ ìš°ì„ )\n",
    "    match = re.search(r'(\\d{4}-(?:\\d{2}|ìˆ˜ëŠ¥)-êµ­ì–´_\\d+)$', source_str)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # ì „ì²´ ì¤‘ ë§ˆì§€ë§‰ ì½”ë“œ ì¶”ì¶œ\n",
    "    all_matches = re.findall(r'(\\d{4}-(?:\\d{2}|ìˆ˜ëŠ¥)-êµ­ì–´_\\d+)', source_str)\n",
    "    return all_matches[-1] if all_matches else None\n",
    "\n",
    "# ì´ë¯¸ì§€ ì €ì¥ ë£¨íŠ¸ í´ë”\n",
    "IMAGE_ROOT = \"/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¬¸í•™/data/output_images\"\n",
    "\n",
    "# ë¬¸ì œ ì´ë¯¸ì§€ ê²½ë¡œ ë°˜í™˜\n",
    "def get_problem_image_path(question_code):\n",
    "    if not question_code:\n",
    "        return None\n",
    "    return os.path.join(IMAGE_ROOT, f\"{question_code}.png\")\n",
    "\n",
    "# ì§€ë¬¸ ì´ë¯¸ì§€ ê²½ë¡œ ë°˜í™˜\n",
    "def get_passage_image_path(passage_code):\n",
    "    if not passage_code:\n",
    "        return None\n",
    "    passage_code = unicodedata.normalize(\"NFC\", passage_code)\n",
    "    match = re.match(r\"(\\d{4}-(?:\\d{2}|ìˆ˜ëŠ¥)-êµ­ì–´)(_p\\d+)\", passage_code)\n",
    "    if not match:\n",
    "        print(f\"âŒ ì§€ë¬¸ ì½”ë“œ íŒŒì‹± ì‹¤íŒ¨: {passage_code}\")\n",
    "        return None\n",
    "    base, p_part = match.groups()\n",
    "    return os.path.join(IMAGE_ROOT, f\"{base}{p_part}.png\")\n",
    "\n",
    "# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì— íƒœê·¸ ë³‘í•©\n",
    "def merge_tags_to_docs(docs, tag_dict):\n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get(\"ì¶œì²˜\") or doc.metadata.get(\"source\")\n",
    "        code = extract_question_code(source)\n",
    "        if not code:\n",
    "            print(f\"âŒ [ë³‘í•© ì‹¤íŒ¨] ì¶œì²˜ ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {source}\")\n",
    "            continue\n",
    "        if code not in tag_dict:\n",
    "            print(f\"âŒ [ë³‘í•© ì‹¤íŒ¨] íƒœê·¸ ì—†ìŒ: {code}\")\n",
    "            continue\n",
    "        doc.metadata[\"question_tags\"] = tag_dict[code]\n",
    "        doc.metadata[\"ì¶œì²˜\"] = code\n",
    "    return docs\n",
    "\n",
    "def tag_similarity_score(user_tags, doc_tags):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì íƒœê·¸(user_tags)ì™€ ë¬¸ì„œ íƒœê·¸(doc_tags)ë¥¼ ë¹„êµí•˜ì—¬ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "    ì ìˆ˜ ë°°ì :\n",
    "    - ë¬¸ì œ ìœ í˜•: 2ì  (ì™„ì „ ì¼ì¹˜ ì‹œ)\n",
    "    - ë³µí•©/ë‹¨ì¼: 2ì  (ì¼ì¹˜ ì‹œ)\n",
    "    - ì§€ë¬¸ ì¥ë¥´: 3ì  (ì™„ì „ ì¼ì¹˜), 2ì  (ìœ ì‚¬ ì¥ë¥´)\n",
    "    - ì§€ë¬¸ ì œëª©: 1ì  (í•˜ë‚˜ë¼ë„ ì¼ì¹˜ ì‹œ)\n",
    "    - ì§€ë¬¸ ì‘ê°€: 1ì  (í•˜ë‚˜ë¼ë„ ì¼ì¹˜ ì‹œ)\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "\n",
    "    # 1) ë¬¸ì œ ìœ í˜• (4ì )\n",
    "    if user_tags.get(\"ë¬¸ì œ ìœ í˜•\") == doc_tags.get(\"ë¬¸ì œ ìœ í˜•\"):\n",
    "        score += 2\n",
    "\n",
    "    # 2) ë³µí•©/ë‹¨ì¼ (2ì )\n",
    "    if user_tags.get(\"ë³µí•©/ë‹¨ì¼\") == doc_tags.get(\"ë³µí•©/ë‹¨ì¼\"):\n",
    "        score += 2\n",
    "\n",
    "    # 3) ì§€ë¬¸ ì¥ë¥´ (5ì  ì™„ì „ ì¼ì¹˜, 2ì  ìœ ì‚¬ ì¥ë¥´)\n",
    "    user_genre = user_tags.get(\"ì§€ë¬¸ ì¥ë¥´\")\n",
    "    doc_genre = doc_tags.get(\"ì§€ë¬¸ ì¥ë¥´\")\n",
    "\n",
    "    if user_genre == doc_genre:\n",
    "        score += 3\n",
    "    else:\n",
    "        # ìœ ì‚¬ ì¥ë¥´ ìŒ (ë¶€ë¶„ ì ìˆ˜)\n",
    "        genre_similarities = [\n",
    "            (\"í˜„ëŒ€ì‹œ\", \"ê³ ì „ ì‹œê°€\"),\n",
    "            (\"ê³ ì „ ì‹œê°€\", \"í˜„ëŒ€ì‹œ\"),\n",
    "            (\"í˜„ëŒ€ ì†Œì„¤\", \"ê³ ì „ ì†Œì„¤\"),\n",
    "            (\"ê³ ì „ ì†Œì„¤\", \"í˜„ëŒ€ ì†Œì„¤\"),\n",
    "        ]\n",
    "        if (user_genre, doc_genre) in genre_similarities or (doc_genre, user_genre) in genre_similarities:\n",
    "            score += 2\n",
    "\n",
    "    # 4) ì§€ë¬¸ ì œëª© (1ì , í•˜ë‚˜ë¼ë„ ê²¹ì¹˜ë©´ ì ìˆ˜ ë¶€ì—¬)\n",
    "    user_title = user_tags.get(\"ì§€ë¬¸ ì œëª©\")\n",
    "    doc_title = doc_tags.get(\"ì§€ë¬¸ ì œëª©\")\n",
    "\n",
    "    if isinstance(user_title, list) and isinstance(doc_title, list):\n",
    "        if set(user_title) & set(doc_title):  # êµì§‘í•©ì´ ìˆìœ¼ë©´\n",
    "            score += 1\n",
    "    elif isinstance(user_title, list):\n",
    "        if doc_title in user_title:\n",
    "            score += 1\n",
    "    elif isinstance(doc_title, list):\n",
    "        if user_title in doc_title:\n",
    "            score += 1\n",
    "    else:\n",
    "        if user_title == doc_title:\n",
    "            score += 1\n",
    "\n",
    "    # 5) ì§€ë¬¸ ì‘ê°€ (1ì , í•˜ë‚˜ë¼ë„ ê²¹ì¹˜ë©´ ì ìˆ˜ ë¶€ì—¬)\n",
    "    user_name = user_tags.get(\"ì§€ë¬¸ ì‘ê°€\")\n",
    "    doc_name = doc_tags.get(\"ì§€ë¬¸ ì‘ê°€\")\n",
    "\n",
    "    if isinstance(user_name, list) and isinstance(doc_name, list):\n",
    "        if set(user_name) & set(doc_name):\n",
    "            score += 1\n",
    "    elif isinstance(user_name, list):\n",
    "        if doc_name in user_name:\n",
    "            score += 1\n",
    "    elif isinstance(doc_name, list):\n",
    "        if user_name in doc_name:\n",
    "            score += 1\n",
    "    else:\n",
    "        if user_name == doc_name:\n",
    "            score += 1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r29OtEQW6QJ"
   },
   "outputs": [],
   "source": [
    "def get_similar_problems_with_images(user_question, retriever, tag_dict, top_k=2):\n",
    "    user_tags = get_tags_from_gpt(user_question)\n",
    "    if user_tags is None:\n",
    "        return []\n",
    "\n",
    "    results = retriever.similarity_search_with_score(user_question, k=20)\n",
    "\n",
    "    docs = []\n",
    "    for doc, score in results:\n",
    "        doc.metadata[\"score\"] = score\n",
    "        docs.append(doc)\n",
    "\n",
    "    docs = merge_tags_to_docs(docs, tag_dict)\n",
    "\n",
    "    docs_with_score = []\n",
    "    for doc in docs:\n",
    "        doc_tags = doc.metadata.get(\"question_tags\")\n",
    "        if not doc_tags:\n",
    "            continue\n",
    "        tag_sim = tag_similarity_score(user_tags, doc_tags)\n",
    "        embedding_sim = doc.metadata.get(\"score\", 0)\n",
    "        final_score = round(tag_sim * 0.7 + embedding_sim * 0.3, 4)\n",
    "        docs_with_score.append((doc, doc_tags, tag_sim, embedding_sim, final_score))\n",
    "\n",
    "    docs_sorted = sorted(docs_with_score, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    similar_problems = []\n",
    "    for i, (doc, doc_tags, tag_sim, emb_sim, final_score) in enumerate(docs_sorted[:top_k]):\n",
    "        question_code = extract_question_code(doc.metadata.get(\"ì¶œì²˜\"))\n",
    "        passage_code = doc_tags.get(\"ì§€ë¬¸\")\n",
    "        problem_img = get_problem_image_path(question_code)\n",
    "        passage_img = get_passage_image_path(passage_code)\n",
    "\n",
    "        similar_problems.append({\n",
    "            \"index\": i + 1,\n",
    "            \"question_code\": question_code,\n",
    "            \"final_score\": final_score,\n",
    "            \"problem_img\": problem_img,\n",
    "            \"passage_img\": passage_img\n",
    "        })\n",
    "\n",
    "    return similar_problems\n",
    "\n",
    "\n",
    "# íƒœê·¸ ë¡œë“œ ë° ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/TAVE í”„ë¡œì íŠ¸_STUBO/ìˆ˜ëŠ¥ êµ­ì–´ AI íŠœí„°ë§ ì‹œìŠ¤í…œ/ë¬¸í•™/data/literature_tagged.json', 'r', encoding='utf-8') as f:\n",
    "    tag_list = json.load(f)\n",
    "\n",
    "tag_dict_literature = {}\n",
    "for item in tag_list:\n",
    "    code = extract_question_code(item.get(\"ì¶œì²˜\"))\n",
    "    if code:\n",
    "        tag_dict_literature[code] = {\n",
    "            \"ì¶œì²˜\": item.get(\"ì¶œì²˜\"),\n",
    "            \"ë¬¸ì œ ìœ í˜•\": item.get(\"ë¬¸ì œ ìœ í˜•\"),\n",
    "            \"ë³µí•©/ë‹¨ì¼\": item.get(\"ë³µí•©/ë‹¨ì¼\"),\n",
    "            \"ì§€ë¬¸ ì œëª©\": item.get(\"ì§€ë¬¸ ì œëª©\"),\n",
    "            \"ì§€ë¬¸ ì¥ë¥´\": item.get(\"ì§€ë¬¸ ì¥ë¥´\"),\n",
    "            \"ì§€ë¬¸ ì‘ê°€\": item.get(\"ì§€ë¬¸ ì‘ê°€\"),\n",
    "            \"ì§€ë¬¸\": item.get(\"ì§€ë¬¸\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjV1l5dew40G"
   },
   "source": [
    "# **<í†µí•© íŒŒì´í”„ë¼ì¸>**\n",
    "1. ë¬¸ì œ ì´ë¯¸ì§€ ì…ë ¥ â†’ OCRë¡œ ë¬¸ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "\n",
    "2. ì§€ë¬¸ ì´ë¯¸ì§€ ì…ë ¥ â†’ OCR í›„ êµ¬ì¡° ë³´ì •ëœ ì§€ë¬¸ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "\n",
    "3. ì •ë‹µ + í•´ì„¤ ìƒì„± (RAG ê¸°ë°˜)\n",
    "\n",
    "4. ìœ ì‚¬ ê¸°ì¶œ ë¬¸ì œ ì¶”ì²œ (ì„ë² ë”© + íƒœê·¸ ê¸°ë°˜)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBuIk6KGw8F9"
   },
   "outputs": [],
   "source": [
    "def pipeline_literature(\n",
    "    question_image_path: str,\n",
    "    passage_image_path: str,\n",
    "    retriever_answer,\n",
    "    retriever_recommend,\n",
    "    tag_dict,\n",
    "    show_images: bool = False,\n",
    "    recommend_top_k: int = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    ğŸ” ë¬¸í•™ ë¬¸ì œ íŒŒì´í”„ë¼ì¸: OCR â†’ ë‹µë³€/í•´ì„¤ â†’ ìœ ì‚¬ë¬¸ì œ ì¶”ì²œ\n",
    "\n",
    "    Parameters:\n",
    "    - question_image_path: ë¬¸ì œ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "    - passage_image_path: ì§€ë¬¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "    - retriever_answer: ë‹µë³€ í•´ì„¤ìš© ë²¡í„°ìŠ¤í† ì–´ retriever\n",
    "    - retriever_recommend: ìœ ì‚¬ë¬¸ì œ ì¶”ì²œìš© retriever\n",
    "    - tag_dict: ê¸°ì¶œ íƒœê·¸ ë”•ì…”ë„ˆë¦¬\n",
    "    - show_images: Streamlitìš© ì´ë¯¸ì§€ ì¶œë ¥ ì—¬ë¶€\n",
    "    - recommend_top_k: ì¶”ì²œí•  ìœ ì‚¬ë¬¸ì œ ìˆ˜\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸ” [1ë‹¨ê³„] ë¬¸ì œ ì´ë¯¸ì§€ OCR ì¶”ì¶œ ì¤‘...\")\n",
    "    question_text = extract_question(question_image_path)\n",
    "\n",
    "    print(\"\\nğŸ” [2ë‹¨ê³„] ì§€ë¬¸ ì´ë¯¸ì§€ OCR ë° ì •êµí™” ì¤‘...\")\n",
    "    passage_text = run_split_pipeline(passage_image_path)\n",
    "\n",
    "    print(\"\\nğŸ§  [3ë‹¨ê³„] ë¬¸ì œ í’€ì´ ë° í•´ì„¤ ìƒì„± ì¤‘...\")\n",
    "    answer_explanation_text = tutor_response(\n",
    "        question=question_text,\n",
    "        passage=passage_text\n",
    "    )\n",
    "\n",
    "    print(\"\\nğŸ“‚ [4ë‹¨ê³„] ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ ì‹¤í–‰ ì¤‘...\")\n",
    "    similar_problem_data = get_similar_problems_with_images(\n",
    "        user_question=question_text,\n",
    "        retriever=retriever_literature_recommend,\n",
    "        tag_dict=tag_dict_literature,\n",
    "        top_k=recommend_top_k\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"question\": question_text,\n",
    "        \"passage\": passage_text,\n",
    "        \"response\": answer_explanation_text,\n",
    "        \"similar_problems\": similar_problem_data\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-BC67ybd_0zG",
    "z4a1G-36bXfE",
    "itQlrdn8GuoV"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
