{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ê¸°ë³¸ install"
      ],
      "metadata": {
        "id": "Wj4GLXcvA6WM"
      },
      "id": "Wj4GLXcvA6WM"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7GgH1nZsVHXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba01a079-36c0-48c4-d00d-d1cf1b531c68"
      },
      "id": "7GgH1nZsVHXF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract PyPDF2"
      ],
      "metadata": {
        "id": "N-FrVyyCcB7u",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d6d383-b132-4c45-c8d6-16cd92c7e7ce"
      },
      "id": "N-FrVyyCcB7u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytesseract, PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1 pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber pdf2image"
      ],
      "metadata": {
        "id": "YaYKByZXYUih",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6354228d-0f06-4b48-d722-c0f2b97c5329"
      },
      "id": "YaYKByZXYUih",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdf2image, pdfminer.six, pdfplumber\n",
            "Successfully installed pdf2image-1.17.0 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407e166e",
      "metadata": {
        "id": "407e166e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/STUBO/ksatparser\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Poppler utilities\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y poppler-utils"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Y7EXRkgIZJlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0a34c1-24d9-43b9-9e22-25f271303d44"
      },
      "id": "Y7EXRkgIZJlG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 9,828 B/129 kB 8%] [Connected to cloud.r-\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 73.5 kB/129 kB 57%] [Connected to cloud.r\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,762 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,119 kB]\n",
            "Fetched 33.6 MB in 4s (7,733 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 0s (1,201 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "z4Du6ChmICK4"
      },
      "id": "z4Du6ChmICK4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lGjWXwhWEBEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb8beb8-bc25-4a75-b14b-16218e58cfbe"
      },
      "id": "lGjWXwhWEBEZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.2.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.1)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easyocr)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easyocr)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easyocr)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easyocr)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easyocr)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easyocr)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 python-bidi-0.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Easy OCR"
      ],
      "metadata": {
        "id": "Jl8E1_LAiezY"
      },
      "id": "Jl8E1_LAiezY"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import easyocr\n",
        "from openai import OpenAI\n",
        "from PIL import Image\n",
        "\n",
        "# âœ… ì„¤ì •\n",
        "image_dir = \"/content/drive/MyDrive/classified_images/ë¹„ë¬¸í•™\"\n",
        "wrong_log_path = \"/content/wrong_answers.json\"\n",
        "client = OpenAI()\n",
        "reader = easyocr.Reader(['ko', 'en'], gpu=True)\n",
        "\n",
        "# âœ… ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\n",
        "def normalize_filename(fn):\n",
        "    return unicodedata.normalize('NFC', fn)\n",
        "\n",
        "# âœ… ì •ë‹µì§€ (JSONì—ì„œ ë¡œë“œí•œ ëŒ€ì‹  ì½”ë“œì— ì§ì ‘ í¬í•¨)\n",
        "true_answers = {\n",
        "    \"2022-03\": {1: \"â‘£\", 2: \"â‘¢\", 3: \"â‘ \", 4: \"â‘¢\", 5: \"â‘¤\", 6: \"â‘¢\", 7: \"â‘¤\", 8: \"â‘ \", 9: \"â‘¤\", 10: \"â‘¡\", 11: \"â‘¢\", 12: \"â‘ \", 13: \"â‘¢\", 14: \"â‘¡\", 15: \"â‘¡\", 16: \"â‘¡\", 17: \"â‘¢\"},\n",
        "    \"2022-06\": {1: \"â‘¤\", 2: \"â‘ \", 3: \"â‘¢\", 4: \"â‘¢\", 5: \"â‘£\", 6: \"â‘£\", 7: \"â‘¡\", 8: \"â‘¡\", 9: \"â‘ \", 10: \"â‘¢\", 11: \"â‘¤\", 12: \"â‘£\", 13: \"â‘¡\", 14: \"â‘ \", 15: \"â‘¡\", 16: \"â‘£\", 17: \"â‘¡\"},\n",
        "    \"2022-09\": {1: \"â‘ \", 2: \"â‘¢\", 3: \"â‘¤\", 4: \"â‘¡\", 5: \"â‘¢\", 6: \"â‘¡\", 7: \"â‘ \", 8: \"â‘¢\", 9: \"â‘¤\", 10: \"â‘¤\", 11: \"â‘£\", 12: \"â‘¤\", 13: \"â‘£\", 14: \"â‘¤\", 15: \"â‘¢\", 16: \"â‘ \", 17: \"â‘ \"},\n",
        "    \"2022-ìˆ˜ëŠ¥\": {1: \"â‘¡\", 2: \"â‘¤\", 3: \"â‘ \", 4: \"â‘ \", 5: \"â‘¢\", 6: \"â‘£\", 7: \"â‘¢\", 8: \"â‘¡\", 9: \"â‘¢\", 10: \"â‘¡\", 11: \"â‘¤\", 12: \"â‘¤\", 13: \"â‘£\", 14: \"â‘£\", 15: \"â‘¡\", 16: \"â‘£\", 17: \"â‘ \"},\n",
        "    \"2023-03\": {1: \"â‘¢\", 2: \"â‘¤\", 3: \"â‘£\", 4: \"â‘£\", 5: \"â‘¡\", 6: \"â‘¤\", 7: \"â‘£\", 8: \"â‘ \", 9: \"â‘£\", 10: \"â‘ \", 11: \"â‘¡\", 12: \"â‘¤\", 13: \"â‘ \", 14: \"â‘¡\", 15: \"â‘¢\", 16: \"â‘¤\", 17: \"â‘¡\"},\n",
        "    \"2023-06\": {1: \"â‘ \", 2: \"â‘¤\", 3: \"â‘£\", 4: \"â‘ \", 5: \"â‘¢\", 6: \"â‘£\", 7: \"â‘ \", 8: \"â‘¡\", 9: \"â‘¢\", 10: \"â‘ \", 11: \"â‘¡\", 12: \"â‘£\", 13: \"â‘¢\", 14: \"â‘ \", 15: \"â‘¤\", 16: \"â‘£\", 17: \"â‘¡\"},\n",
        "    \"2023-09\": {1: \"â‘ \", 2: \"â‘£\", 3: \"â‘ \", 4: \"â‘¢\", 5: \"â‘ \", 6: \"â‘¤\", 7: \"â‘¤\", 8: \"â‘¢\", 9: \"â‘ \", 10: \"â‘¡\", 11: \"â‘£\", 12: \"â‘¡\", 13: \"â‘£\", 14: \"â‘¡\", 15: \"â‘¤\", 16: \"â‘¤\", 17: \"â‘ \"},\n",
        "    \"2023-ìˆ˜ëŠ¥\": {1: \"â‘£\", 2: \"â‘¤\", 3: \"â‘ \", 4: \"â‘£\", 5: \"â‘¤\", 6: \"â‘¢\", 7: \"â‘¡\", 8: \"â‘¤\", 9: \"â‘¡\", 10: \"â‘£\", 11: \"â‘¤\", 12: \"â‘¡\", 13: \"â‘¤\", 14: \"â‘¢\", 15: \"â‘£\", 16: \"â‘£\", 17: \"â‘ \"},\n",
        "    \"2024-03\": {1: \"â‘ \", 2: \"â‘¡\", 3: \"â‘¡\", 4: \"â‘¢\", 5: \"â‘¢\", 6: \"â‘ \", 7: \"â‘¡\", 8: \"â‘¡\", 9: \"â‘ \", 10: \"â‘ \", 11: \"â‘¢\", 12: \"â‘¢\", 13: \"â‘¢\", 14: \"â‘¢\", 15: \"â‘¡\", 16: \"â‘¤\", 17: \"â‘£\"},\n",
        "    \"2024-06\": {1: \"â‘¡\", 2: \"â‘¤\", 3: \"â‘ \", 4: \"â‘¡\", 5: \"â‘£\", 6: \"â‘¤\", 7: \"â‘¤\", 8: \"â‘¡\", 9: \"â‘ \", 10: \"â‘£\", 11: \"â‘¢\", 12: \"â‘ \", 13: \"â‘¢\", 14: \"â‘ \", 15: \"â‘¡\", 16: \"â‘¢\", 17: \"â‘£\"},\n",
        "    \"2024-09\": {1: \"â‘¡\", 2: \"â‘¢\", 3: \"â‘¢\", 4: \"â‘¢\", 5: \"â‘¤\", 6: \"â‘£\", 7: \"â‘ \", 8: \"â‘¤\", 9: \"â‘£\", 10: \"â‘¤\", 11: \"â‘¡\", 12: \"â‘£\", 13: \"â‘¤\", 14: \"â‘¢\", 15: \"â‘¤\", 16: \"â‘¤\", 17: \"â‘ \"},\n",
        "    \"2024-ìˆ˜ëŠ¥\": {1: \"â‘¤\", 2: \"â‘¢\", 3: \"â‘ \", 4: \"â‘¤\", 5: \"â‘¢\", 6: \"â‘¡\", 7: \"â‘¡\", 8: \"â‘¢\", 9: \"â‘ \", 10: \"â‘¤\", 11: \"â‘¡\", 12: \"â‘¢\", 13: \"â‘ \", 14: \"â‘£\", 15: \"â‘£\", 16: \"â‘¤\", 17: \"â‘£\"},\n",
        "    \"2025-03\": {1: \"â‘¡\", 2: \"â‘£\", 3: \"â‘£\", 4: \"â‘¡\", 5: \"â‘¢\", 6: \"â‘¢\", 7: \"â‘¡\", 8: \"â‘¤\", 9: \"â‘ \", 10: \"â‘¤\", 11: \"â‘£\", 12: \"â‘¤\", 13: \"â‘¢\", 14: \"â‘¡\", 15: \"â‘ \", 16: \"â‘ \", 17: \"â‘¤\"},\n",
        "    \"2025-06\": {1: \"â‘¤\", 2: \"â‘¡\", 3: \"â‘¡\", 4: \"â‘ \", 5: \"â‘¤\", 6: \"â‘¡\", 7: \"â‘ \", 8: \"â‘£\", 9: \"â‘ \", 10: \"â‘¢\", 11: \"â‘¢\", 12: \"â‘£\", 13: \"â‘¤\", 14: \"â‘£\", 15: \"â‘ \", 16: \"â‘ \", 17: \"â‘¡\"},\n",
        "    \"2025-09\": {1: \"â‘£\", 2: \"â‘¤\", 3: \"â‘¡\", 4: \"â‘£\", 5: \"â‘£\", 6: \"â‘¢\", 7: \"â‘ \", 8: \"â‘£\", 9: \"â‘¤\", 10: \"â‘¡\", 11: \"â‘¢\", 12: \"â‘ \", 13: \"â‘¢\", 14: \"â‘¤\", 15: \"â‘ \", 16: \"â‘¤\", 17: \"â‘ \"},\n",
        "    \"2025-ìˆ˜ëŠ¥\": {1: \"â‘¢\", 2: \"â‘£\", 3: \"â‘¤\", 4: \"â‘£\", 5: \"â‘¤\", 6: \"â‘¢\", 7: \"â‘¡\", 8: \"â‘ \", 9: \"â‘¡\", 10: \"â‘¢\", 11: \"â‘ \", 12: \"â‘¤\", 13: \"â‘¢\", 14: \"â‘ \", 15: \"â‘¡\", 16: \"â‘¡\", 17: \"â‘¢\"},\n",
        "}\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "def extract_text_with_underlines(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    results = reader.readtext(gray, detail=True)\n",
        "\n",
        "    full_text = \" \".join([text for (_, text, _) in results])\n",
        "    return re.sub(r'\\b1[\\.\\)]', 'â‘ ', full_text)\\\n",
        "             .replace('2.', 'â‘¡')\\\n",
        "             .replace('3.', 'â‘¢')\\\n",
        "             .replace('4.', 'â‘£')\\\n",
        "             .replace('5.', 'â‘¤')\\\n",
        "             .strip()\n",
        "\n",
        "\n",
        "# âœ… GPT í”„ë¡¬í”„íŠ¸\n",
        "text_prompt = '''\n",
        "ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "1. ì§ˆë¬¸ ì¡°ê±´ì„ ì •í™•íˆ ë°˜ì˜í•´ ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”.\n",
        "2. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
        "3. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.\n",
        "\n",
        "ì•„ë˜ ì´ë¯¸ì§€ëŠ” ë¬¸í•™ ë¬¸ì œ í•˜ë‚˜ì˜ 'ì§ˆë¬¸ ë¬¸ì¥ + â‘ ~â‘¤ ì„ íƒì§€'ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ì•¼.\n",
        "    ë§Œì•½ <ë³´ê¸°> ë¬¸ì¥ì´ ì¡´ì¬í•œë‹¤ë©´ ì§ˆë¬¸ ì•ì— ìœ„ì¹˜í•˜ë©°, ë°˜ë“œì‹œ í¬í•¨í•´ì„œ ì¶œë ¥í•´.\n",
        "\n",
        "    í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥í•´:\n",
        "\n",
        "    (ì§ˆë¬¸ê³¼ <ë³´ê¸°> ë‚´ìš©. <ë³´ê¸°>ê°€ ì—†ë‹¤ë©´ ìƒëµ)\n",
        "    â‘  ...\n",
        "    â‘¡ ...\n",
        "    â‘¢ ...\n",
        "    â‘£ ...\n",
        "    â‘¤ ...\n",
        "\n",
        "    â— ì ˆëŒ€ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì§€ ë§ê³  í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.\n",
        "\n",
        "[ì§€ë¬¸]\n",
        "{passage}\n",
        "\n",
        "[ë¬¸ì œ]\n",
        "{question}\n",
        "\n",
        "ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
        "\n",
        "[ì •ë‹µ] â‘¢\n",
        "[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)\n",
        "\n",
        "'''\n",
        "\n",
        "# âœ… GPT ì‹¤í–‰ ë° íŒŒì‹±\n",
        "def ask_gpt(prompt_text):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def parse_gpt_output(output):\n",
        "    a = re.search(r'\\[ì •ë‹µ\\]\\s*([â‘ -â‘¤])', output)\n",
        "    e = re.search(r'\\[í•´ì„¤\\](.*)', output, re.DOTALL)\n",
        "    return (a.group(1) if a else None), (e.group(1).strip() if e else \"\")\n",
        "\n",
        "# âœ… ì˜¤ë‹µ ì €ì¥\n",
        "def log_wrong_answer(qid, gpt_answer, true_answer, passage, question, explanation):\n",
        "    entry = {\n",
        "        \"ë¬¸ì œID\": qid,\n",
        "        \"GPT_ì •ë‹µ\": gpt_answer,\n",
        "        \"ì‹¤ì œì •ë‹µ\": true_answer,\n",
        "        \"ì§€ë¬¸\": passage,\n",
        "        \"ë¬¸ì œ\": question,\n",
        "        \"GPT_í•´ì„¤\": explanation\n",
        "    }\n",
        "    if os.path.exists(wrong_log_path):\n",
        "        with open(wrong_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = []\n",
        "    data.append(entry)\n",
        "    with open(wrong_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… ë§¤í•‘\n",
        "def get_mapping(year, month):\n",
        "    special = (year, month) in [(2024, \"06\"), (2024, \"09\"), (2024, \"ìˆ˜ëŠ¥\"), (2025, \"06\"), (2025, \"09\")]\n",
        "    return {\n",
        "        \"p1\": [1, 2, 3],\n",
        "        \"p2\": list(range(4, 8)) if special else list(range(4, 10)),\n",
        "        \"p3\": list(range(8, 12)) if special else list(range(10, 14)),\n",
        "        \"p4\": list(range(12, 18)) if special else list(range(14, 18))\n",
        "    }\n",
        "\n",
        "# âœ… ì‹¤í–‰ ëŒ€ìƒ\n",
        "target_sets = [\n",
        "    #(2022, \"03\"), (2022, \"06\"), (2022, \"09\"), (2022, \"ìˆ˜ëŠ¥\"),\n",
        "    #(2023, \"03\"), (2023, \"06\"), (2023, \"09\"), (2023, \"ìˆ˜ëŠ¥\"),\n",
        "    #(2024, \"03\"), (2024, \"06\"), (2024, \"09\"), (2024, \"ìˆ˜ëŠ¥\"),\n",
        "    #(2025, \"03\"), (2025, \"06\"), (2025, \"09\"),  (2025, \"ìˆ˜ëŠ¥\")\n",
        "    (2025, \"06\"), (2025, \"09\"),  (2025, \"ìˆ˜ëŠ¥\")\n",
        "]\n",
        "\n",
        "wrong = 0\n",
        "\n",
        "# âœ… ì‹¤í–‰ ë£¨í”„\n",
        "for year, month in target_sets:\n",
        "    exam_key = f\"{year}-{month}\"\n",
        "    if exam_key not in true_answers:\n",
        "        print(f\"âš ï¸ ì •ë‹µ ì—†ìŒ: {exam_key}\")\n",
        "        continue\n",
        "\n",
        "    mapping = get_mapping(year, month)\n",
        "    for p_key, q_nums in mapping.items():\n",
        "        p_path = normalize_filename(f\"{year}-{month}-êµ­ì–´_{p_key}.png\")\n",
        "        p_img = os.path.join(image_dir, p_path)\n",
        "        if not os.path.exists(p_img):\n",
        "            print(f\"âŒ ì§€ë¬¸ ì´ë¯¸ì§€ ì—†ìŒ: {p_img}\")\n",
        "            continue\n",
        "        passage = extract_text_with_underlines(p_img)\n",
        "\n",
        "        for qn in q_nums:\n",
        "            q_path = normalize_filename(f\"{year}-{month}-êµ­ì–´_{qn}.png\")\n",
        "            q_img = os.path.join(image_dir, q_path)\n",
        "            if not os.path.exists(q_img):\n",
        "                print(f\"âŒ ë¬¸ì œ ì´ë¯¸ì§€ ì—†ìŒ: {q_img}\")\n",
        "                continue\n",
        "\n",
        "            question = extract_text_with_underlines(q_img)\n",
        "            prompt = text_prompt.format(passage=passage, question=question)\n",
        "            print(f\"\\nğŸ“˜ [{exam_key} / ë¬¸ì œ {qn}]\")\n",
        "\n",
        "            try:\n",
        "                gpt_output = ask_gpt(prompt)\n",
        "                gpt_ans, explanation = parse_gpt_output(gpt_output)\n",
        "                true_ans = true_answers[exam_key].get(qn)\n",
        "\n",
        "                print(f\"GPT: {gpt_ans}, ì •ë‹µ: {true_ans}\")\n",
        "                if gpt_ans != true_ans:\n",
        "                    print(\"âŒ ì˜¤ë‹µ ê¸°ë¡\")\n",
        "                    wrong += 1\n",
        "                    qid = f\"{exam_key}-{qn}\"\n",
        "                    log_wrong_answer(qid, gpt_ans, true_ans, passage, question, explanation)\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ GPT ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(f\"\\nâœ… ì˜¤ë‹µ ê°œìˆ˜: {wrong}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bdc3ef-8b5a-459f-db79-f4960b638f69",
        "id": "dznTcgVAwENG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 1]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 2]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 3]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 4]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 5]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 6]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 7]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 8]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 9]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 10]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 11]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 12]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 13]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 14]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 15]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 16]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 17]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 1]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 2]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 3]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 4]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 5]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 6]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 7]\n",
            "GPT: â‘£, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 8]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘£\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 9]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 10]\n",
            "GPT: â‘£, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 11]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 12]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 13]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 14]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 15]\n",
            "GPT: â‘£, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 16]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 17]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 1]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 2]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 3]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¤\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 4]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 5]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 6]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 7]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 8]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 9]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 10]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 11]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 12]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 13]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 14]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 15]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 16]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 17]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "âœ… ì˜¤ë‹µ ê°œìˆ˜: 18\n"
          ]
        }
      ],
      "id": "dznTcgVAwENG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì •ì œëœ í…ìŠ¤íŠ¸ **(2025-06)**"
      ],
      "metadata": {
        "id": "OqGYunvh9bAC"
      },
      "id": "OqGYunvh9bAC"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import unicodedata\n",
        "\n",
        "# âœ… ì„¤ì •\n",
        "text_path = \"/content/2025-06.txt\"\n",
        "wrong_log_path = \"/content/wrong_answers.json\"\n",
        "client = OpenAI()\n",
        "\n",
        "true_answers = {\n",
        "    \"2025-06\": {\n",
        "        1: \"â‘¤\", 2: \"â‘¡\", 3: \"â‘¡\", 4: \"â‘ \", 5: \"â‘¤\", 6: \"â‘¡\", 7: \"â‘ \",\n",
        "        8: \"â‘£\", 9: \"â‘ \", 10: \"â‘¢\", 11: \"â‘¢\", 12: \"â‘£\", 13: \"â‘¤\", 14: \"â‘£\",\n",
        "        15: \"â‘ \", 16: \"â‘ \", 17: \"â‘¡\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê°•ì¡°, <ë³´ê¸°>, [ë³´ê¸°] ëª¨ë‘ ìœ ì§€)\n",
        "text_prompt = '''\n",
        "ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "1. ì‹¤ì œ ì§€ë¬¸ ë‚´ìš©ê³¼ ì„ íƒì§€ë³„ ì£¼ì¥ ë° ê²°ê³¼ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€,\n",
        "2. ë°˜ë“œì‹œ ê° ì„ ì§€ë³„ë¡œ ë¶€í•©í•˜ë©´ â€˜Oâ€™, ì–´ê¸‹ë‚˜ë©´ ëª…í™•í•˜ê²Œ â€˜Xâ€™ë¡œ ì±„ì í•˜ê³ ,\n",
        "3. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
        "4. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.\n",
        "\n",
        "ì§€ë¬¸ì—ëŠ” **ê°•ì¡°**ëœ ë‹¨ì–´, <êµ¬ê°„> ë¬¸ì¥, [ë³´ê¸°] ë¬¸ì¥ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì•„ë˜ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”:\n",
        "\n",
        "[ì§€ë¬¸]\n",
        "{passage}\n",
        "\n",
        "[ë¬¸ì œ]\n",
        "{question}\n",
        "\n",
        "ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
        "\n",
        "[ì •ë‹µ] â‘¢\n",
        "[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)\n",
        "'''\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±\n",
        "def parse_text_by_blocks(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # ì§€ë¬¸ êµ¬ê°„ ë¶„ë¦¬ (ì˜ˆ: [1~3], [4~7] ...)\n",
        "    raw_blocks = re.split(r'\\[(\\d+ï½\\d+)\\]', content)\n",
        "    passages = []\n",
        "    i = 1\n",
        "    while i < len(raw_blocks):\n",
        "        range_str = raw_blocks[i]\n",
        "        body = raw_blocks[i+1].strip()\n",
        "        start, end = map(int, range_str.split('ï½'))\n",
        "        questions = []\n",
        "\n",
        "        # ë¬¸ì œ ë‹¨ë½ ë¶„ë¦¬ (<ë³´ê¸°> í¬í•¨ ê°€ëŠ¥)\n",
        "        q_splits = re.split(r'\\n\\s*(\\d{1,2})\\.\\s', body)\n",
        "        q_texts = []\n",
        "        j = 1\n",
        "        while j < len(q_splits):\n",
        "            q_num = int(q_splits[j])\n",
        "            q_body = q_splits[j+1].strip()\n",
        "            q_texts.append((q_num, q_body))\n",
        "            j += 2\n",
        "\n",
        "        passages.append({\n",
        "            \"range\": (start, end),\n",
        "            \"text\": q_splits[0].strip(),  # ì§€ë¬¸ ë¶€ë¶„\n",
        "            \"questions\": q_texts\n",
        "        })\n",
        "        i += 2\n",
        "\n",
        "    return passages\n",
        "\n",
        "# âœ… GPT ì‹¤í–‰ ë° íŒŒì‹±\n",
        "def ask_gpt(prompt_text):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def parse_gpt_output(output):\n",
        "    a = re.search(r'\\[ì •ë‹µ\\]\\s*([â‘ -â‘¤])', output)\n",
        "    e = re.search(r'\\[í•´ì„¤\\](.*)', output, re.DOTALL)\n",
        "    return (a.group(1) if a else None), (e.group(1).strip() if e else \"\")\n",
        "\n",
        "# âœ… ì˜¤ë‹µ ê¸°ë¡\n",
        "def log_wrong_answer(qid, gpt_answer, true_answer, passage, question, explanation):\n",
        "    entry = {\n",
        "        \"ë¬¸ì œID\": qid,\n",
        "        \"GPT_ì •ë‹µ\": gpt_answer,\n",
        "        \"ì‹¤ì œì •ë‹µ\": true_answer,\n",
        "        \"ì§€ë¬¸\": passage,\n",
        "        \"ë¬¸ì œ\": question,\n",
        "        \"GPT_í•´ì„¤\": explanation\n",
        "    }\n",
        "    if os.path.exists(wrong_log_path):\n",
        "        with open(wrong_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = []\n",
        "    data.append(entry)\n",
        "    with open(wrong_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… ì‹¤í–‰\n",
        "exam_key = \"2025-06\"\n",
        "wrong = 0\n",
        "blocks = parse_text_by_blocks(text_path)\n",
        "\n",
        "for block in blocks:\n",
        "    passage = block[\"text\"]\n",
        "    for qn, question in block[\"questions\"]:\n",
        "        prompt = text_prompt.format(passage=passage, question=question)\n",
        "        print(f\"\\nğŸ“˜ [{exam_key} / ë¬¸ì œ {qn}]\")\n",
        "        try:\n",
        "            gpt_output = ask_gpt(prompt)\n",
        "            gpt_ans, explanation = parse_gpt_output(gpt_output)\n",
        "            true_ans = true_answers[exam_key].get(qn)\n",
        "\n",
        "            print(f\"GPT: {gpt_ans}, ì •ë‹µ: {true_ans}\")\n",
        "            if gpt_ans != true_ans:\n",
        "                print(\"âŒ ì˜¤ë‹µ ê¸°ë¡\")\n",
        "                wrong += 1\n",
        "                qid = f\"{exam_key}-{qn}\"\n",
        "                log_wrong_answer(qid, gpt_ans, true_ans, passage, question, explanation)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ GPT ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(f\"\\nâœ… ì˜¤ë‹µ ê°œìˆ˜: {wrong}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0U52pBoFmhm",
        "outputId": "89c66906-3c79-4006-e672-1f19226d6b79"
      },
      "id": "p0U52pBoFmhm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 1]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 2]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 3]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 4]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 5]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 6]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 7]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 8]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 9]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 10]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 11]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 12]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 13]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 14]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 15]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 16]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 17]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "âœ… ì˜¤ë‹µ ê°œìˆ˜: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "íŒíŠ¸ì¶”ê°€ (7ë²ˆ)"
      ],
      "metadata": {
        "id": "xF2kEwIZGXjx"
      },
      "id": "xF2kEwIZGXjx"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import unicodedata\n",
        "\n",
        "# âœ… ì„¤ì •\n",
        "text_path = \"/content/2025-06.txt\"\n",
        "wrong_log_path = \"/content/wrong_answers.json\"\n",
        "client = OpenAI()\n",
        "\n",
        "true_answers = {\n",
        "    \"2025-06\": {\n",
        "        1: \"â‘¤\", 2: \"â‘¡\", 3: \"â‘¡\", 4: \"â‘ \", 5: \"â‘¤\", 6: \"â‘¡\", 7: \"â‘ \",\n",
        "        8: \"â‘£\", 9: \"â‘ \", 10: \"â‘¢\", 11: \"â‘¢\", 12: \"â‘£\", 13: \"â‘¤\", 14: \"â‘£\",\n",
        "        15: \"â‘ \", 16: \"â‘ \", 17: \"â‘¡\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê°•ì¡°, <ë³´ê¸°>, [ë³´ê¸°] ëª¨ë‘ ìœ ì§€)\n",
        "text_prompt = '''\n",
        "ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "1. ì‹¤ì œ ì§€ë¬¸ ë‚´ìš©ê³¼ ì„ íƒì§€ë³„ ì£¼ì¥ ë° ê²°ê³¼ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€,\n",
        "2. ë°˜ë“œì‹œ ê° ì„ ì§€ë³„ë¡œ ë¶€í•©í•˜ë©´ â€˜Oâ€™, ì–´ê¸‹ë‚˜ë©´ ëª…í™•í•˜ê²Œ â€˜Xâ€™ë¡œ ì±„ì í•˜ê³ ,\n",
        "3. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
        "4. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.\n",
        "\n",
        "ì§€ë¬¸ì—ëŠ” **ê°•ì¡°**ëœ ë‹¨ì–´, <êµ¬ê°„> ë¬¸ì¥, [ë³´ê¸°] ë¬¸ì¥ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì•„ë˜ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”:\n",
        "\n",
        "[ì§€ë¬¸]\n",
        "{passage}\n",
        "\n",
        "[ë¬¸ì œ]\n",
        "{question}\n",
        "\n",
        "ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
        "\n",
        "[ì •ë‹µ] â‘¢\n",
        "[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)\n",
        "'''\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±\n",
        "def parse_text_by_blocks(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # ì§€ë¬¸ êµ¬ê°„ ë¶„ë¦¬ (ì˜ˆ: [1~3], [4~7] ...)\n",
        "    raw_blocks = re.split(r'\\[(\\d+ï½\\d+)\\]', content)\n",
        "    passages = []\n",
        "    i = 1\n",
        "    while i < len(raw_blocks):\n",
        "        range_str = raw_blocks[i]\n",
        "        body = raw_blocks[i+1].strip()\n",
        "        start, end = map(int, range_str.split('ï½'))\n",
        "        questions = []\n",
        "\n",
        "        # ë¬¸ì œ ë‹¨ë½ ë¶„ë¦¬ (<ë³´ê¸°> í¬í•¨ ê°€ëŠ¥)\n",
        "        q_splits = re.split(r'\\n\\s*(\\d{1,2})\\.\\s', body)\n",
        "        q_texts = []\n",
        "        j = 1\n",
        "        while j < len(q_splits):\n",
        "            q_num = int(q_splits[j])\n",
        "            q_body = q_splits[j+1].strip()\n",
        "            q_texts.append((q_num, q_body))\n",
        "            j += 2\n",
        "\n",
        "        passages.append({\n",
        "            \"range\": (start, end),\n",
        "            \"text\": q_splits[0].strip(),  # ì§€ë¬¸ ë¶€ë¶„\n",
        "            \"questions\": q_texts\n",
        "        })\n",
        "        i += 2\n",
        "\n",
        "    return passages\n",
        "\n",
        "# âœ… GPT ì‹¤í–‰ ë° íŒŒì‹±\n",
        "def ask_gpt(prompt_text):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def parse_gpt_output(output):\n",
        "    a = re.search(r'\\[ì •ë‹µ\\]\\s*([â‘ -â‘¤])', output)\n",
        "    e = re.search(r'\\[í•´ì„¤\\](.*)', output, re.DOTALL)\n",
        "    return (a.group(1) if a else None), (e.group(1).strip() if e else \"\")\n",
        "\n",
        "# âœ… ì˜¤ë‹µ ê¸°ë¡\n",
        "def log_wrong_answer(qid, gpt_answer, true_answer, passage, question, explanation):\n",
        "    entry = {\n",
        "        \"ë¬¸ì œID\": qid,\n",
        "        \"GPT_ì •ë‹µ\": gpt_answer,\n",
        "        \"ì‹¤ì œì •ë‹µ\": true_answer,\n",
        "        \"ì§€ë¬¸\": passage,\n",
        "        \"ë¬¸ì œ\": question,\n",
        "        \"GPT_í•´ì„¤\": explanation\n",
        "    }\n",
        "    if os.path.exists(wrong_log_path):\n",
        "        with open(wrong_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = []\n",
        "    data.append(entry)\n",
        "    with open(wrong_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… ì‹¤í–‰\n",
        "exam_key = \"2025-06\"\n",
        "wrong = 0\n",
        "blocks = parse_text_by_blocks(text_path)\n",
        "\n",
        "for block in blocks:\n",
        "    passage = block[\"text\"]\n",
        "    for qn, question in block[\"questions\"]:\n",
        "        prompt = text_prompt.format(passage=passage, question=question)\n",
        "        print(f\"\\nğŸ“˜ [{exam_key} / ë¬¸ì œ {qn}]\")\n",
        "        try:\n",
        "            gpt_output = ask_gpt(prompt)\n",
        "            gpt_ans, explanation = parse_gpt_output(gpt_output)\n",
        "            true_ans = true_answers[exam_key].get(qn)\n",
        "\n",
        "            print(f\"GPT: {gpt_ans}, ì •ë‹µ: {true_ans}\")\n",
        "            if gpt_ans != true_ans:\n",
        "                print(\"âŒ ì˜¤ë‹µ ê¸°ë¡\")\n",
        "                wrong += 1\n",
        "                qid = f\"{exam_key}-{qn}\"\n",
        "                log_wrong_answer(qid, gpt_ans, true_ans, passage, question, explanation)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ GPT ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(f\"\\nâœ… ì˜¤ë‹µ ê°œìˆ˜: {wrong}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrSnUitEGajH",
        "outputId": "fbbd4d2d-4f5c-486d-ad30-a77d7d623a3e"
      },
      "id": "WrSnUitEGajH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 1]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 2]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 3]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 4]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 5]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 6]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 7]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 8]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 9]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 10]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 11]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 12]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 13]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 14]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 15]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 16]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-06 / ë¬¸ì œ 17]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "âœ… ì˜¤ë‹µ ê°œìˆ˜: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì •ì œëœ í…ìŠ¤íŠ¸ **(2025-09)**"
      ],
      "metadata": {
        "id": "Hh_5aj55J3uI"
      },
      "id": "Hh_5aj55J3uI"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import unicodedata\n",
        "\n",
        "# âœ… ì„¤ì •\n",
        "text_path = \"/content/2025-09.txt\"\n",
        "wrong_log_path = \"/content/wrong_answers.json\"\n",
        "client = OpenAI()\n",
        "\n",
        "true_answers = {\n",
        "    \"2025-09\": {1: \"â‘£\", 2: \"â‘¤\", 3: \"â‘¡\", 4: \"â‘£\", 5: \"â‘£\", 6: \"â‘¢\", 7: \"â‘ \", 8: \"â‘£\", 9: \"â‘¤\", 10: \"â‘¡\", 11: \"â‘¢\", 12: \"â‘ \", 13: \"â‘¢\", 14: \"â‘¤\", 15: \"â‘ \", 16: \"â‘¤\", 17: \"â‘ \"},\n",
        "\n",
        "}\n",
        "\n",
        "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê°•ì¡°, <ë³´ê¸°>, [ë³´ê¸°] ëª¨ë‘ ìœ ì§€)\n",
        "text_prompt = '''\n",
        "ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "1. ì‹¤ì œ ì§€ë¬¸ ë‚´ìš©ê³¼ ì„ íƒì§€ë³„ ì£¼ì¥ ë° ê²°ê³¼ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€,\n",
        "2. ë°˜ë“œì‹œ ê° ì„ ì§€ë³„ë¡œ ë¶€í•©í•˜ë©´ â€˜Oâ€™, ì–´ê¸‹ë‚˜ë©´ ëª…í™•í•˜ê²Œ â€˜Xâ€™ë¡œ ì±„ì í•˜ê³ ,\n",
        "3. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
        "4. ì„ íƒì§€ ì¤‘ í¬ê´„ê´€ê³„, ê´€ê³„ì—­ì „ ì˜¤ë¥˜ë¥¼ ì£¼ì˜í•˜ì„¸ìš”.\n",
        "5. ì–´íœ˜ ë¬¸ë§¥ íŒë‹¨ ë¬¸ì œì—ì„œëŠ” ì‚¬ì „ì  ì˜ë¯¸ë¥¼ íŒë‹¨í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.\n",
        "4. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.\n",
        "\n",
        "ì§€ë¬¸ì—ëŠ” **ê°•ì¡°**ëœ ë‹¨ì–´, <êµ¬ê°„> ë¬¸ì¥, [ë³´ê¸°] ë¬¸ì¥ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì•„ë˜ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”:\n",
        "\n",
        "[ì§€ë¬¸]\n",
        "{passage}\n",
        "\n",
        "[ë¬¸ì œ]\n",
        "{question}\n",
        "\n",
        "ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
        "\n",
        "[ì •ë‹µ] â‘¢\n",
        "[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)\n",
        "'''\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±\n",
        "def parse_text_by_blocks(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # ì§€ë¬¸ êµ¬ê°„ ë¶„ë¦¬ (ì˜ˆ: [1~3], [4~7] ...)\n",
        "    raw_blocks = re.split(r'\\[(\\d+ï½\\d+)\\]', content)\n",
        "    passages = []\n",
        "    i = 1\n",
        "    while i < len(raw_blocks):\n",
        "        range_str = raw_blocks[i]\n",
        "        body = raw_blocks[i+1].strip()\n",
        "        start, end = map(int, range_str.split('ï½'))\n",
        "        questions = []\n",
        "\n",
        "        # ë¬¸ì œ ë‹¨ë½ ë¶„ë¦¬ (<ë³´ê¸°> í¬í•¨ ê°€ëŠ¥)\n",
        "        q_splits = re.split(r'\\n\\s*(\\d{1,2})\\.\\s', body)\n",
        "        q_texts = []\n",
        "        j = 1\n",
        "        while j < len(q_splits):\n",
        "            q_num = int(q_splits[j])\n",
        "            q_body = q_splits[j+1].strip()\n",
        "            q_texts.append((q_num, q_body))\n",
        "            j += 2\n",
        "\n",
        "        passages.append({\n",
        "            \"range\": (start, end),\n",
        "            \"text\": q_splits[0].strip(),  # ì§€ë¬¸ ë¶€ë¶„\n",
        "            \"questions\": q_texts\n",
        "        })\n",
        "        i += 2\n",
        "\n",
        "    return passages\n",
        "\n",
        "# âœ… GPT ì‹¤í–‰ ë° íŒŒì‹±\n",
        "def ask_gpt(prompt_text):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def parse_gpt_output(output):\n",
        "    a = re.search(r'\\[ì •ë‹µ\\]\\s*([â‘ -â‘¤])', output)\n",
        "    e = re.search(r'\\[í•´ì„¤\\](.*)', output, re.DOTALL)\n",
        "    return (a.group(1) if a else None), (e.group(1).strip() if e else \"\")\n",
        "\n",
        "# âœ… ì˜¤ë‹µ ê¸°ë¡\n",
        "def log_wrong_answer(qid, gpt_answer, true_answer, passage, question, explanation):\n",
        "    entry = {\n",
        "        \"ë¬¸ì œID\": qid,\n",
        "        \"GPT_ì •ë‹µ\": gpt_answer,\n",
        "        \"ì‹¤ì œì •ë‹µ\": true_answer,\n",
        "        \"ì§€ë¬¸\": passage,\n",
        "        \"ë¬¸ì œ\": question,\n",
        "        \"GPT_í•´ì„¤\": explanation\n",
        "    }\n",
        "    if os.path.exists(wrong_log_path):\n",
        "        with open(wrong_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = []\n",
        "    data.append(entry)\n",
        "    with open(wrong_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… ì‹¤í–‰\n",
        "exam_key = \"2025-09\"\n",
        "wrong = 0\n",
        "blocks = parse_text_by_blocks(text_path)\n",
        "\n",
        "for block in blocks:\n",
        "    passage = block[\"text\"]\n",
        "    for qn, question in block[\"questions\"]:\n",
        "        prompt = text_prompt.format(passage=passage, question=question)\n",
        "        print(f\"\\nğŸ“˜ [{exam_key} / ë¬¸ì œ {qn}]\")\n",
        "        try:\n",
        "            gpt_output = ask_gpt(prompt)\n",
        "            gpt_ans, explanation = parse_gpt_output(gpt_output)\n",
        "            true_ans = true_answers[exam_key].get(qn)\n",
        "\n",
        "            print(f\"GPT: {gpt_ans}, ì •ë‹µ: {true_ans}\")\n",
        "            if gpt_ans != true_ans:\n",
        "                print(\"âŒ ì˜¤ë‹µ ê¸°ë¡\")\n",
        "                wrong += 1\n",
        "                qid = f\"{exam_key}-{qn}\"\n",
        "                log_wrong_answer(qid, gpt_ans, true_ans, passage, question, explanation)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ GPT ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(f\"\\nâœ… ì˜¤ë‹µ ê°œìˆ˜: {wrong}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fce9e07-f62c-4ad0-a118-842bdb58393f",
        "id": "Fja9uGPzJ3uJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 1]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 2]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 3]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 4]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 5]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 6]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 7]\n",
            "GPT: â‘£, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 8]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘£\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 9]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 10]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 11]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 12]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 13]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 14]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 15]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 16]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 17]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "âœ… ì˜¤ë‹µ ê°œìˆ˜: 2\n"
          ]
        }
      ],
      "id": "Fja9uGPzJ3uJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "íŒíŠ¸ ì¶”ê°€"
      ],
      "metadata": {
        "id": "KGr0o_buSjNl"
      },
      "id": "KGr0o_buSjNl"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import unicodedata\n",
        "\n",
        "# âœ… ì„¤ì •\n",
        "text_path = \"/content/2025-09.txt\"\n",
        "wrong_log_path = \"/content/wrong_answers.json\"\n",
        "client = OpenAI()\n",
        "\n",
        "true_answers = {\n",
        "    \"2025-09\": {1: \"â‘£\", 2: \"â‘¤\", 3: \"â‘¡\", 4: \"â‘£\", 5: \"â‘£\", 6: \"â‘¢\", 7: \"â‘ \", 8: \"â‘£\", 9: \"â‘¤\", 10: \"â‘¡\", 11: \"â‘¢\", 12: \"â‘ \", 13: \"â‘¢\", 14: \"â‘¤\", 15: \"â‘ \", 16: \"â‘¤\", 17: \"â‘ \"},\n",
        "\n",
        "}\n",
        "\n",
        "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê°•ì¡°, <ë³´ê¸°>, [ë³´ê¸°] ëª¨ë‘ ìœ ì§€)\n",
        "text_prompt = '''\n",
        "ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "1. ì‹¤ì œ ì§€ë¬¸ ë‚´ìš©ê³¼ ì„ íƒì§€ë³„ ì£¼ì¥ ë° ê²°ê³¼ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€,\n",
        "2. ë°˜ë“œì‹œ ê° ì„ ì§€ë³„ë¡œ ë¶€í•©í•˜ë©´ â€˜Oâ€™, ì–´ê¸‹ë‚˜ë©´ ëª…í™•í•˜ê²Œ â€˜Xâ€™ë¡œ ì±„ì í•˜ê³ ,\n",
        "3. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
        "4. ì„ íƒì§€ ì¤‘ í¬ê´„ê´€ê³„, ê´€ê³„ì—­ì „ ì˜¤ë¥˜ë¥¼ ì£¼ì˜í•˜ì„¸ìš”.\n",
        "5. ì–´íœ˜ ë¬¸ë§¥ íŒë‹¨ ë¬¸ì œì—ì„œëŠ” ì‚¬ì „ì  ì˜ë¯¸ë¥¼ íŒë‹¨í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.\n",
        "4. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.\n",
        "\n",
        "ì§€ë¬¸ì—ëŠ” **ê°•ì¡°**ëœ ë‹¨ì–´, <êµ¬ê°„> ë¬¸ì¥, [ë³´ê¸°] ë¬¸ì¥ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì•„ë˜ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”:\n",
        "\n",
        "[ì§€ë¬¸]\n",
        "{passage}\n",
        "\n",
        "[ë¬¸ì œ]\n",
        "{question}\n",
        "\n",
        "ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
        "\n",
        "[ì •ë‹µ] â‘¢\n",
        "[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)\n",
        "'''\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±\n",
        "def parse_text_by_blocks(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # ì§€ë¬¸ êµ¬ê°„ ë¶„ë¦¬ (ì˜ˆ: [1~3], [4~7] ...)\n",
        "    raw_blocks = re.split(r'\\[(\\d+ï½\\d+)\\]', content)\n",
        "    passages = []\n",
        "    i = 1\n",
        "    while i < len(raw_blocks):\n",
        "        range_str = raw_blocks[i]\n",
        "        body = raw_blocks[i+1].strip()\n",
        "        start, end = map(int, range_str.split('ï½'))\n",
        "        questions = []\n",
        "\n",
        "        # ë¬¸ì œ ë‹¨ë½ ë¶„ë¦¬ (<ë³´ê¸°> í¬í•¨ ê°€ëŠ¥)\n",
        "        q_splits = re.split(r'\\n\\s*(\\d{1,2})\\.\\s', body)\n",
        "        q_texts = []\n",
        "        j = 1\n",
        "        while j < len(q_splits):\n",
        "            q_num = int(q_splits[j])\n",
        "            q_body = q_splits[j+1].strip()\n",
        "            q_texts.append((q_num, q_body))\n",
        "            j += 2\n",
        "\n",
        "        passages.append({\n",
        "            \"range\": (start, end),\n",
        "            \"text\": q_splits[0].strip(),  # ì§€ë¬¸ ë¶€ë¶„\n",
        "            \"questions\": q_texts\n",
        "        })\n",
        "        i += 2\n",
        "\n",
        "    return passages\n",
        "\n",
        "# âœ… GPT ì‹¤í–‰ ë° íŒŒì‹±\n",
        "def ask_gpt(prompt_text):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def parse_gpt_output(output):\n",
        "    a = re.search(r'\\[ì •ë‹µ\\]\\s*([â‘ -â‘¤])', output)\n",
        "    e = re.search(r'\\[í•´ì„¤\\](.*)', output, re.DOTALL)\n",
        "    return (a.group(1) if a else None), (e.group(1).strip() if e else \"\")\n",
        "\n",
        "# âœ… ì˜¤ë‹µ ê¸°ë¡\n",
        "def log_wrong_answer(qid, gpt_answer, true_answer, passage, question, explanation):\n",
        "    entry = {\n",
        "        \"ë¬¸ì œID\": qid,\n",
        "        \"GPT_ì •ë‹µ\": gpt_answer,\n",
        "        \"ì‹¤ì œì •ë‹µ\": true_answer,\n",
        "        \"ì§€ë¬¸\": passage,\n",
        "        \"ë¬¸ì œ\": question,\n",
        "        \"GPT_í•´ì„¤\": explanation\n",
        "    }\n",
        "    if os.path.exists(wrong_log_path):\n",
        "        with open(wrong_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = []\n",
        "    data.append(entry)\n",
        "    with open(wrong_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… ì‹¤í–‰\n",
        "exam_key = \"2025-09\"\n",
        "wrong = 0\n",
        "blocks = parse_text_by_blocks(text_path)\n",
        "\n",
        "for block in blocks:\n",
        "    passage = block[\"text\"]\n",
        "    for qn, question in block[\"questions\"]:\n",
        "        prompt = text_prompt.format(passage=passage, question=question)\n",
        "        print(f\"\\nğŸ“˜ [{exam_key} / ë¬¸ì œ {qn}]\")\n",
        "        try:\n",
        "            gpt_output = ask_gpt(prompt)\n",
        "            gpt_ans, explanation = parse_gpt_output(gpt_output)\n",
        "            true_ans = true_answers[exam_key].get(qn)\n",
        "\n",
        "            print(f\"GPT: {gpt_ans}, ì •ë‹µ: {true_ans}\")\n",
        "            if gpt_ans != true_ans:\n",
        "                print(\"âŒ ì˜¤ë‹µ ê¸°ë¡\")\n",
        "                wrong += 1\n",
        "                qid = f\"{exam_key}-{qn}\"\n",
        "                log_wrong_answer(qid, gpt_ans, true_ans, passage, question, explanation)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ GPT ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(f\"\\nâœ… ì˜¤ë‹µ ê°œìˆ˜: {wrong}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84550ad7-af4b-436b-a971-b4b33be90033",
        "id": "gfelwu7FJ3uN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 1]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 2]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 3]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 4]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 5]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 6]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 7]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 8]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 9]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 10]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 11]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 12]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 13]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 14]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 15]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 16]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-09 / ë¬¸ì œ 17]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "âœ… ì˜¤ë‹µ ê°œìˆ˜: 0\n"
          ]
        }
      ],
      "id": "gfelwu7FJ3uN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì •ì œëœ í…ìŠ¤íŠ¸ **(2025-ìˆ˜ëŠ¥)**"
      ],
      "metadata": {
        "id": "NQZL2BwkTHpX"
      },
      "id": "NQZL2BwkTHpX"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import unicodedata\n",
        "\n",
        "# âœ… ì„¤ì •\n",
        "text_path = \"/content/2025-ìˆ˜ëŠ¥.txt\"\n",
        "wrong_log_path = \"/content/wrong_answers(2025-ìˆ˜ëŠ¥).json\"\n",
        "client = OpenAI()\n",
        "\n",
        "true_answers = {\n",
        "    \"2025-ìˆ˜ëŠ¥\": {1: \"â‘¢\", 2: \"â‘£\", 3: \"â‘¤\", 4: \"â‘£\", 5: \"â‘¤\", 6: \"â‘¢\", 7: \"â‘¡\", 8: \"â‘ \", 9: \"â‘¡\", 10: \"â‘¢\", 11: \"â‘ \", 12: \"â‘¤\", 13: \"â‘¢\", 14: \"â‘ \", 15: \"â‘¡\", 16: \"â‘¡\", 17: \"â‘¢\"},\n",
        "}\n",
        "\n",
        "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê°•ì¡°, <ë³´ê¸°>, [ë³´ê¸°] ëª¨ë‘ ìœ ì§€)\n",
        "text_prompt = '''\n",
        "ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "1. ì‹¤ì œ ì§€ë¬¸ ë‚´ìš©ê³¼ ì„ íƒì§€ë³„ ì£¼ì¥ ë° ê²°ê³¼ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€,\n",
        "2. ë°˜ë“œì‹œ ê° ì„ ì§€ë³„ë¡œ ë¶€í•©í•˜ë©´ â€˜Oâ€™, ì–´ê¸‹ë‚˜ë©´ ëª…í™•í•˜ê²Œ â€˜Xâ€™ë¡œ ì±„ì í•˜ê³ ,\n",
        "3. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
        "4. ì„ íƒì§€ ì¤‘ í¬ê´„ê´€ê³„, ê´€ê³„ì—­ì „ ì˜¤ë¥˜ë¥¼ ì£¼ì˜í•˜ì„¸ìš”.\n",
        "5. ì–´íœ˜ ë¬¸ë§¥ íŒë‹¨ ë¬¸ì œì—ì„œëŠ” ì‚¬ì „ì  ì˜ë¯¸ë¥¼ íŒë‹¨í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.\n",
        "4. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.\n",
        "\n",
        "ì§€ë¬¸ì—ëŠ” **ê°•ì¡°**ëœ ë‹¨ì–´, <êµ¬ê°„> ë¬¸ì¥, [ë³´ê¸°] ë¬¸ì¥ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì•„ë˜ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”:\n",
        "\n",
        "[ì§€ë¬¸]\n",
        "{passage}\n",
        "\n",
        "[ë¬¸ì œ]\n",
        "{question}\n",
        "\n",
        "ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
        "\n",
        "[ì •ë‹µ] â‘¢\n",
        "[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)\n",
        "'''\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±\n",
        "def parse_text_by_blocks(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # ì§€ë¬¸ êµ¬ê°„ ë¶„ë¦¬ (ì˜ˆ: [1~3], [4~7] ...)\n",
        "    raw_blocks = re.split(r'\\[(\\d+ï½\\d+)\\]', content)\n",
        "    passages = []\n",
        "    i = 1\n",
        "    while i < len(raw_blocks):\n",
        "        range_str = raw_blocks[i]\n",
        "        body = raw_blocks[i+1].strip()\n",
        "        start, end = map(int, range_str.split('ï½'))\n",
        "        questions = []\n",
        "\n",
        "        # ë¬¸ì œ ë‹¨ë½ ë¶„ë¦¬ (<ë³´ê¸°> í¬í•¨ ê°€ëŠ¥)\n",
        "        q_splits = re.split(r'\\n\\s*(\\d{1,2})\\.\\s', body)\n",
        "        q_texts = []\n",
        "        j = 1\n",
        "        while j < len(q_splits):\n",
        "            q_num = int(q_splits[j])\n",
        "            q_body = q_splits[j+1].strip()\n",
        "            q_texts.append((q_num, q_body))\n",
        "            j += 2\n",
        "\n",
        "        passages.append({\n",
        "            \"range\": (start, end),\n",
        "            \"text\": q_splits[0].strip(),  # ì§€ë¬¸ ë¶€ë¶„\n",
        "            \"questions\": q_texts\n",
        "        })\n",
        "        i += 2\n",
        "\n",
        "    return passages\n",
        "\n",
        "# âœ… GPT ì‹¤í–‰ ë° íŒŒì‹±\n",
        "def ask_gpt(prompt_text):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def parse_gpt_output(output):\n",
        "    a = re.search(r'\\[ì •ë‹µ\\]\\s*([â‘ -â‘¤])', output)\n",
        "    e = re.search(r'\\[í•´ì„¤\\](.*)', output, re.DOTALL)\n",
        "    return (a.group(1) if a else None), (e.group(1).strip() if e else \"\")\n",
        "\n",
        "# âœ… ì˜¤ë‹µ ê¸°ë¡\n",
        "def log_wrong_answer(qid, gpt_answer, true_answer, passage, question, explanation):\n",
        "    entry = {\n",
        "        \"ë¬¸ì œID\": qid,\n",
        "        \"GPT_ì •ë‹µ\": gpt_answer,\n",
        "        \"ì‹¤ì œì •ë‹µ\": true_answer,\n",
        "        \"ì§€ë¬¸\": passage,\n",
        "        \"ë¬¸ì œ\": question,\n",
        "        \"GPT_í•´ì„¤\": explanation\n",
        "    }\n",
        "    if os.path.exists(wrong_log_path):\n",
        "        with open(wrong_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = []\n",
        "    data.append(entry)\n",
        "    with open(wrong_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# âœ… ì‹¤í–‰\n",
        "exam_key = \"2025-ìˆ˜ëŠ¥\"\n",
        "wrong = 0\n",
        "blocks = parse_text_by_blocks(text_path)\n",
        "\n",
        "for block in blocks:\n",
        "    passage = block[\"text\"]\n",
        "    for qn, question in block[\"questions\"]:\n",
        "        prompt = text_prompt.format(passage=passage, question=question)\n",
        "        print(f\"\\nğŸ“˜ [{exam_key} / ë¬¸ì œ {qn}]\")\n",
        "        try:\n",
        "            gpt_output = ask_gpt(prompt)\n",
        "            gpt_ans, explanation = parse_gpt_output(gpt_output)\n",
        "            true_ans = true_answers[exam_key].get(qn)\n",
        "\n",
        "            print(f\"GPT: {gpt_ans}, ì •ë‹µ: {true_ans}\")\n",
        "            if gpt_ans != true_ans:\n",
        "                print(\"âŒ ì˜¤ë‹µ ê¸°ë¡\")\n",
        "                wrong += 1\n",
        "                qid = f\"{exam_key}-{qn}\"\n",
        "                log_wrong_answer(qid, gpt_ans, true_ans, passage, question, explanation)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ GPT ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(f\"\\nâœ… ì˜¤ë‹µ ê°œìˆ˜: {wrong}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0f3a02-db02-4ff6-d804-f8a916ea29e2",
        "id": "BmvbgALzTHpa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 1]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 2]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 3]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 4]\n",
            "GPT: â‘£, ì •ë‹µ: â‘£\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 5]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 6]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 7]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 8]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘ \n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 9]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 10]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 11]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 12]\n",
            "GPT: â‘¤, ì •ë‹µ: â‘¤\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 13]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 14]\n",
            "GPT: â‘ , ì •ë‹µ: â‘ \n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 15]\n",
            "GPT: â‘¡, ì •ë‹µ: â‘¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 16]\n",
            "GPT: â‘£, ì •ë‹µ: â‘¡\n",
            "âŒ ì˜¤ë‹µ ê¸°ë¡\n",
            "\n",
            "ğŸ“˜ [2025-ìˆ˜ëŠ¥ / ë¬¸ì œ 17]\n",
            "GPT: â‘¢, ì •ë‹µ: â‘¢\n",
            "\n",
            "âœ… ì˜¤ë‹µ ê°œìˆ˜: 3\n"
          ]
        }
      ],
      "id": "BmvbgALzTHpa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Wj4GLXcvA6WM",
        "Jl8E1_LAiezY",
        "OqGYunvh9bAC",
        "Hh_5aj55J3uI"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}